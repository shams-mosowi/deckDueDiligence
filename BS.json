{"nodes":[{"id":"2b8fa1ef-7853-451e-8376-78452c84407b","nodes":{"h23hj4":[{"groupInfo":null,"_libRef":{"buildHash":"2a7320471dd016f3f1eb5b26f75abf25666f8e021ce0d8e86bbac34dcdaff403","libNodeRefId":"@buildship/scrape-web-url","integrity":"v3:ded1bfa955e8462a048a98b68383d460","isDirty":false,"libType":"public","version":"5.0.0","src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/scrape-web-url/5.0.0/build.cjs"},"inputs":{"required":["selector","url"],"properties":{"url":{"description":"The url to scrape.","default":"https://buildship.com/","title":"URL","pattern":"","properties":{},"buildship":{"sensitive":false,"index":0},"type":"string"},"selector":{"title":"Selector","buildship":{"sensitive":false,"index":1},"default":"body","pattern":"","type":"string","description":"A valid HTML selector."}},"type":"object"},"dependencies":{"axios":"1.6.2","cheerio":"1.0.0-rc.12"},"type":"script","integrity":"v3:ded1bfa955e8462a048a98b68383d460","id":"f48c51d2-fe21-4f6b-b7cd-310a3fdbac72","meta":{"id":"scrape-web-url","name":"Scrape Web URL","icon":{"type":"SVG","svg":"<path d=\"M20 18c1.1 0 1.99-.9 1.99-2L22 6c0-1.11-.9-2-2-2H4c-1.11 0-2 .89-2 2v10c0 1.1.89 2 2 2H0v2h24v-2h-4ZM4 16V6h16v10.01L4 16Zm5.0967-6.0469c0-1.027.836-1.864 1.864-1.864 1.027 0 1.864.837 1.864 1.864 0 1.027-.837 1.864-1.864 1.864-1.028 0-1.864-.837-1.864-1.864Zm7.032 4.236-2.482-2.482c.331-.505.527-1.107.527-1.754 0-1.772-1.441-3.213-3.213-3.213s-3.214 1.441-3.214 3.213 1.442 3.214 3.214 3.214c.636 0 1.225-.192 1.724-.511l2.489 2.488.955-.955Z\"></path>"},"description":"Scrape a given web url and return the text content"},"script":"import axios from \"axios\";\nimport cheerio from \"cheerio\";\n\nexport default async function scrapeUrl({ url, selector }: NodeInputs) : NodeOutput  {\n  const { data } = await axios.get(url);\n\n  const $ = cheerio.load(data);\n\n  $(\"script\").remove();\n\n  const content = $(selector).text().replace(/\\n/g, \"\");\n\n  return content\n}","label":"Scrape Web URL","src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/scrape-web-url/5.0.0/build.cjs","integrations":[],"_createdBy":{"isAnonymous":false,"displayName":"Luis Rodge","email":"luis@rowy.io.rowy","emailVerified":true,"uid":"5pCgHZpkCmTSRrtmK9Ld7emLKLJ2","timestamp":{"_seconds":1695139729,"_nanoseconds":504000000},"photoURL":"https://lh3.googleusercontent.com/a/AGNmyxaoKyi1YHoiusuLWh9sPHGzirW-H-miXcE4eOey=s96-c"},"output":{"type":"string","buildship":{"index":0},"title":"Content","description":"Scrapped Website Content"},"version":"5.0.0"}],"h23hj5":[{"inputs":{"type":"object","properties":{"pdfUrl":{"pattern":"","default":"","title":"PDF Url","description":"PDF URL, if not fetching from a path in cloud storage.","buildship":{"index":1,"sensitive":false},"type":"string"},"pdfPath":{"pattern":"","description":"PDF file path in the cloud storage, if not fetching from the URL.\n\nQUICK TIP 💡: Upload your PDF file using the **Upload File** node.","buildship":{"sensitive":false,"index":0},"default":"","title":"PDF Path","type":"string"}},"required":[]},"script":"import fs from 'fs';\nimport pdf from '@cyber2024/pdf-parse-fixed';\nimport axios from 'axios'\n\nexport default async function pdfToText({ pdfPath, pdfUrl }: NodeInputs, { logging }: NodeScriptOptions) : NodeOutput  {\n  if (!pdfPath && !pdfUrl) throw Error(\"You must specify either a pdf path or pdf url.\")\n  \n  let dataBuffer;\n  if (pdfUrl) {\n    const response = await axios.get(pdfUrl, {\n      responseType: 'arraybuffer'\n    });\n    dataBuffer = response.data\n  } else {\n    const localPath = process.env.BUCKET_FOLDER_PATH + pdfPath\n    dataBuffer = fs.readFileSync(localPath);\n  }\n  const data = await pdf(dataBuffer)\n  return data.text\n}","output":{"buildship":{"index":0},"type":"string"},"type":"script","_createdBy":{"timestamp":{"_seconds":1695075951,"_nanoseconds":223000000},"uid":"5pCgHZpkCmTSRrtmK9Ld7emLKLJ2","emailVerified":true,"photoURL":"https://lh3.googleusercontent.com/a/AGNmyxaoKyi1YHoiusuLWh9sPHGzirW-H-miXcE4eOey=s96-c","isAnonymous":false,"email":"luis@rowy.io.rowy","displayName":"Luis Rodge"},"meta":{"name":"PDF To Text","id":"pdf-to-text","description":"Convert a PDF from local storage or url to text.","icon":{"type":"SVG","svg":"<path d=\"M20 2H8c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm-8.5 7.5c0 .83-.67 1.5-1.5 1.5H9v1.25c0 .41-.34.75-.75.75s-.75-.34-.75-.75V8c0-.55.45-1 1-1H10c.83 0 1.5.67 1.5 1.5v1zm5 2c0 .83-.67 1.5-1.5 1.5h-2c-.28 0-.5-.22-.5-.5v-5c0-.28.22-.5.5-.5h2c.83 0 1.5.67 1.5 1.5v3zm4-3.75c0 .41-.34.75-.75.75H19v1h.75c.41 0 .75.34.75.75s-.34.75-.75.75H19v1.25c0 .41-.34.75-.75.75s-.75-.34-.75-.75V8c0-.55.45-1 1-1h1.25c.41 0 .75.34.75.75zM9 9.5h1v-1H9v1zM3 6c-.55 0-1 .45-1 1v13c0 1.1.9 2 2 2h13c.55 0 1-.45 1-1s-.45-1-1-1H5c-.55 0-1-.45-1-1V7c0-.55-.45-1-1-1zm11 5.5h1v-3h-1v3z\"></path>"}},"version":"5.0.0","dependencies":{"fs":"0.0.1-security","axios":"1.6.2","@cyber2024/pdf-parse-fixed":"1.2.5"},"src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/pdf-to-text/5.0.0/build.cjs","integrity":"v3:49374ae6699f473e0ac660c008693733","_libRef":{"integrity":"v3:49374ae6699f473e0ac660c008693733","libType":"public","version":"5.0.0","isDirty":true,"src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/pdf-to-text/5.0.0/build.cjs","buildHash":"54a5a1397217b1ae8c28a354744c77e229f184a000667e11fd107f2d78ef9b7a","libNodeRefId":"@buildship/pdf-to-text"},"id":"568e4227-7450-4a8b-a861-59b4455d48bf","groupInfo":null,"integrations":[],"label":"PDF To Text"}]},"type":"parallel","description":"The Parallel node allows you to run multiple nodes simultaneously. It is useful for executing independent logic in parallel, saving valuable time in your workflow. \n\nKey Features:  \n- Processes input elements concurrently, unlike series processing, which runs sequentially.  \n- Useful for tasks like making multiple API calls at once.  \n- Concurrency limits depend on your BuildShip plan, please check the [pricing page](https://buildship.com/pricing) to see the maximum concurrency limit for your plan. \n\nLearn more about the Parallel node: [Docs](https://docs.buildship.com/core-nodes/parallel)","label":"extraction"},{"nodes":{"5ga8m":[{"id":"3176f735-4d90-4933-b3c9-9e8d2c2b058b","_groupInfo":{"uid":"openai","longDescription":"BuildShip allows you to effortlessly integrate OpenAI models into your workflows, enabling the use of advanced machine learning capabilities for text generation, translation, and more. Streamline processes by utilizing AI-powered models to enhance automation, decision-making, and content generation in a seamless and efficient manner.","keyDescription":"Add your OpenAI API Key. Get it from your [OpenAI account](https://platform.openai.com/account/api-keys)","details":null,"id":"ZBwcODUEhzNMxYxpN1O8","acceptsKey":true,"iconUrl":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fopenai.png?alt=media&token=9c513dd1-e2d4-47d2-8e3c-3a1a6ebf03e3","icon":null,"category":"AI Models","description":"OpenAI Models","name":"OpenAI"},"inputs":{"sections":{"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982":{"title":"Advanced","type":"section","buildship":{"collapsed":true,"index":3}}},"properties":{"maxTokens":{"description":"The maximum length (in tokens) of the generated JSON.","type":"number","default":800,"pattern":"","title":"Max Tokens","buildship":{"sensitive":false,"index":3.2}},"temperature":{"buildship":{"sensitive":false,"index":3.3},"default":0.1,"description":"As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions.\n\n**RANGE: `0 to 1`**","type":"number","properties":{},"pattern":"","title":"Temperature"},"response_schema":{"properties":{},"type":"object","title":"Schema","buildship":{"index":2,"defaultExpressionType":"schema","sensitive":false},"default":{"type":"schema","_$schema_":[{"required":true,"type":"string","name":"weather"},{"type":"number","name":"temperature","required":true},{"name":"description","type":"string","required":true},{"required":true,"type":"boolean","name":"isRaining"}],"_$expression_":""},"pattern":"","description":"The response schema can be created using the Schema Builder.\n\nIt can also be created as a plain object in the JavaScript editor and it should be in a standard JSON Schema format.\n\n```\n{\n  \"type\": \"json_schema\",\n  \"json_schema\": {\n    \"name\": \"response\",\n    \"strict\": true,\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {},\n      \"required\": [],\n      \"additionalProperties\": false,\n      \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    },\n  },\n}\n```\n"},"userPrompt":{"description":"The user prompt to generate JSON from.","properties":{},"type":"string","default":"The weather today is sunny with a temperature of 75 degrees.","pattern":"","title":"Input","buildship":{"sensitive":false,"index":1,"placeholder":"Your Unstructured Text"}},"systemPrompt":{"default":"Convert the input text into JSON following the schema exactly.","description":"The system prompt to generate JSON from.\n\n**When using this node, always instruct the model to produce JSON using the provided Schema.**\n\n**SAMPLE PROMPT**:\n```\nYou are a helpful math tutor. Only use the schema for math responses.\n```","title":"Instructions","pattern":"","properties":{},"type":"string","buildship":{"sensitive":false,"placeholder":"","index":0}},"model":{"type":"string","description":"The OpenAI Model to use for performing the JSON Generation.","title":"Model","buildship":{"index":3.4,"defaultExpressionType":"text","options":[{"label":"gpt-4.1","value":"gpt-4.1"},{"value":"gpt-4o-mini","label":"gpt-4o-mini"},{"label":"gpt-4o","value":"gpt-4o"}],"sensitive":false},"enum":["gpt-4.1","gpt-4o-mini","gpt-4o"],"pattern":"","properties":{},"default":"gpt-4o-2024-08-06"}},"required":["apiKey","systemPrompt","userPrompt","response_schema","model"],"type":"object","structure":[{"depth":0,"index":0,"parentId":null,"id":"systemPrompt"},{"id":"userPrompt","index":1,"depth":0,"parentId":null},{"index":2,"parentId":null,"id":"response_schema","depth":0},{"id":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982","children":[{"depth":1,"index":0,"parentId":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982","id":"maxTokens"},{"index":1,"parentId":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982","id":"temperature","depth":1},{"index":2,"parentId":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982","id":"model","depth":1}],"index":3,"parentId":null,"depth":0}]},"label":"Parsed deck and site","_libRef":{"isDirty":true,"libNodeRefId":"@buildship/openai-json-schema-generator","integrity":"v3:b0f8e77b632793a3ae59c684f8258821","version":"2.1.11","libType":"public","buildHash":"2d4824f0e396200f8e154ff90d9af6879d4a8bd750b16fda5f95861c7a72ddca","src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/openai-json-schema-generator/2.1.11/build.cjs"},"script":"import OpenAI from \"openai\";\n\nconst getAccessToken = async () => {\n  const response = await fetch(\n    \"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n    { headers: { \"Metadata-Flavor\": \"Google\" } }\n  );\n  if (!response.ok) {\n    throw new Error(`Failed to obtain access token: ${response.statusText}`);\n  }\n  const data: any = await response.json();\n  return data?.access_token;\n};\n\nexport default async function openaiGptTextGenerator(\n  {\n    userPrompt,\n    systemPrompt,\n    maxTokens,\n    temperature,\n    model,\n    response_schema,\n    kbIntegrationKey,\n  }: NodeInputs & { kbIntegrationKey: string },\n  { auth, workflow, node }: NodeScriptOptions\n): NodeOutput {\n  const hasCredits = kbIntegrationKey?.split(\";;\")[1] === \"credits\";\n  const apiKey = hasCredits ? await getAccessToken() : auth.getKey();\n\n  if (!apiKey) {\n    throw new Error(\n      \"An integration key is required for this node to function, but no key was selected. Please select one from the node's toolbar.\"\n    );\n  }\n\n  const client = new OpenAI({\n    apiKey,\n    ...(hasCredits && { baseURL: \"https://proxy.buildship.run/llm/openai\" }),\n  });\n\n\n  const response = await client.responses.create(\n    {\n      model,\n      input: [\n        {\n          role: \"system\",\n          content: systemPrompt,\n        },\n        {\n          role: \"user\",\n          content: userPrompt,\n        },\n      ],\n      text: {\n        format: transformResponseSchema(response_schema),\n      },\n      max_output_tokens: maxTokens,\n      temperature,\n    },\n    hasCredits\n      ? {\n          headers: {\n            \"x-buildship-workflow-id\": workflow?.id,\n            \"x-buildship-node-id\": node?.id,\n          },\n        }\n      : undefined\n  );\n\n  try {\n    return JSON.parse(response.output_text);\n  } catch (e) {\n    throw new Error(\"Failed to parse response output_text as JSON.\");\n  }\n}\n\n\nfunction transformResponseSchema(response_schema: any) {\n  if (!response_schema?.json_schema?.schema) {\n    throw new Error(\"Invalid or missing response_schema format.\");\n  }\n\n  const UNSUPPORTED_BY_TYPE: Record<string, string[]> = {\n    string: [\"minLength\", \"maxLength\", \"pattern\", \"format\"],\n    number: [\"minimum\", \"maximum\", \"multipleOf\"],\n    object: [\n      \"patternProperties\", \"unevaluatedProperties\", \"propertyNames\",\n      \"minProperties\", \"maxProperties\"\n    ],\n    array: [\n      \"unevaluatedItems\", \"contains\", \"minContains\", \"maxContains\",\n      \"minItems\", \"maxItems\", \"uniqueItems\"\n    ],\n  };\n\n  const clean = (schema: any, inProps = false): any => {\n    if (Array.isArray(schema)) return schema.map((s) => clean(s, inProps));\n    if (typeof schema !== \"object\" || schema === null) return schema;\n\n    const type = schema.type;\n    const unsupported = inProps ? [] : (UNSUPPORTED_BY_TYPE[type] || []);\n    \n    return Object.fromEntries(\n      Object.entries(schema).map(([k, v]) => {\n        if (unsupported.includes(k)) return null;\n        const nested = k === \"properties\" ? clean(v, true) : clean(v, false);\n        return [k, nested];\n      }).filter(Boolean)\n    );\n  };\n\n  return {\n    type: \"json_schema\",\n    name: response_schema.json_schema.name || \"response\",\n    strict: true,\n    schema: clean(response_schema.json_schema.schema),\n  };\n}\n","meta":{"name":"JSON Generator","icon":{"url":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fopenai.png?alt=media&token=9c513dd1-e2d4-47d2-8e3c-3a1a6ebf03e3&_gl=1*b90bgk*_ga*MjAxOTYxMjk5OS4xNjk0NTIzMjQ2*_ga_CW55HF8NVT*MTY5NjQwMzEyMy4yNS4xLjE2OTY0MDMxNDQuMzkuMC4w","type":"URL"},"description":"A keyless node that generates perfectly structured JSON using OpenAI's Structured Outputs, ensuring strict adherence to a provided schema.","id":"openai-json-schema-generator"},"integrations":[],"buildshipKey":true,"output":{"properties":{"moat":{"buildship":{"index":1},"type":"string","title":"moat"},"traction":{"buildship":{"index":5},"type":"string","title":"traction"},"summery":{"title":"summery","buildship":{"index":3},"type":"string"},"market":{"type":"string","title":"market","buildship":{"index":2}},"keyDifferentiation":{"title":"keyDifferentiation","type":"string","buildship":{"index":4}},"team":{"buildship":{"index":0},"type":"array","title":"team","properties":{"object":{"properties":{"name":{"title":"name","type":"string","buildship":{"index":0}},"role":{"title":"role","buildship":{"index":1},"type":"string"}},"buildship":{"index":0},"title":"object","type":"object"}}}},"buildship":{"index":0},"type":"object"},"type":"script","dependencies":{"openai":"4.95.0"}},{"nodes":[{"id":"d965b4ec-47db-4e69-a1e8-e5563f63f7c8","label":"Parallel","type":"parallel","nodes":{"syi1ru":[{"script":"import OpenAI from \"openai\";\nimport fs from \"fs\";\nimport path from \"path\";\n\nconst getAccessToken = async () => {\n  const response = await fetch(\n    \"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n    {\n      headers: { \"Metadata-Flavor\": \"Google\" },\n    }\n  );\n  if (!response.ok) {\n    throw new Error(`Failed to obtain access token: ${response.statusText}`);\n  }\n  const data = await response.json();\n  return data.access_token;\n};\n\nexport default async (\n  {\n    userRequest,\n    systemPrompt,\n    model,\n    temperature,\n    sessionKey,\n    conversationLimit,\n    maxTokens,\n    outputFormat,\n    kbIntegrationKey,\n  },\n  { logging, workflow, node, auth }\n) => {\n  const openai = kbIntegrationKey?.split(\";;\")[1] === \"credits\" ?\n    new OpenAI({\n    baseURL: \"https://proxy.buildship.run/llm/diffbot\",\n    apiKey: await getAccessToken(),\n  }) : new OpenAI({\n    apiKey: auth.getKey(),\n  });\n\n  let previousMessages = [];\n  const filePath =\n    process.env.BUCKET_FOLDER_PATH +\n    \"/nodes/openai-chat/store/\" +\n    sessionKey +\n    \".jsonl\";\n  if (sessionKey && fs.existsSync(filePath)) {\n    const fileContent = fs.readFileSync(filePath, \"utf-8\");\n    const lines = fileContent.trim().split(\"\\n\").slice(-conversationLimit);\n    for (const line of lines) {\n      const { userRequest, assistantResponse } = JSON.parse(line);\n      previousMessages.push({ role: \"user\", content: userRequest });\n      previousMessages.push({ role: \"assistant\", content: assistantResponse });\n    }\n  }\n\n  const jsonInstruction = \"##Output a valid JSON Object##.\\n\";\n  const response = await openai.chat.completions.create(\n    {\n      model,\n      temperature,\n      max_tokens: maxTokens,\n      messages: [\n        {\n          role: \"system\",\n          content:\n            outputFormat === \"json_object\"\n              ? jsonInstruction + systemPrompt\n              : systemPrompt,\n        },\n        ...previousMessages,\n        { role: \"user\", content: userRequest },\n      ],\n      ...(outputFormat === \"json_object\" && {\n        response_format: { type: \"json_object\" },\n      }),\n    },\n    {\n      ...(kbIntegrationKey?.split(\";;\")[1] === \"credits\"\n        ? {\n            headers: {\n              \"x-buildship-workflow-id\": workflow?.id,\n              \"x-buildship-node-id\": node?.id,\n            },\n          }\n        : {}),\n    }\n  );\n\n  const output = response.choices[0].message.content;\n  if (sessionKey) {\n    const folderPath = path.dirname(filePath);\n    if (!fs.existsSync(folderPath)) {\n      fs.mkdirSync(folderPath, { recursive: true });\n    }\n    const dataToSave = { userRequest, assistantResponse: output };\n    fs.appendFileSync(filePath, JSON.stringify(dataToSave) + \"\\n\");\n  }\n  return output;\n};\n","id":"8cfd7e60-42b8-43ce-aa1b-8b6ce7b99542","inputs":{"required":["userRequest","model"],"properties":{"model":{"properties":{},"title":"Model","default":"diffbot-small-xl","type":"string","enum":["diffbot-small-xl"],"buildship":{"sensitive":false,"index":2.2,"options":[{"label":"diffbot-small-xl","value":"diffbot-small-xl"}],"defaultExpressionType":"text"}},"userRequest":{"title":"Prompt","default":"Generate 5 tools for AI agents to call via an API that handle specific business tasks, with a one-sentence summary of inputs, logic flows (leveraging LLMs, image, or data / knowledge base analysis), external connections needed, and expected outputs.","properties":{},"description":"The prompt to send to the assistant as user message.","buildship":{"sensitive":false,"index":1,"defaultExpressionType":"text"},"type":"string"},"sessionKey":{"buildship":{"sensitive":false,"defaultExpressionType":"text","placeholder":"session-xyz-123","index":2.3},"description":"Key to save and load conversation history.","type":"string","title":"Session Key","properties":{},"default":""},"maxTokens":{"type":"number","title":"Max Tokens","properties":{},"buildship":{"defaultExpressionType":"text","index":2.6,"sensitive":false},"default":1600},"outputFormat":{"properties":{},"enum":["text","json_object"],"description":"Select the format of the output.","buildship":{"options":[{"label":"Text","value":"text"},{"value":"json_object","label":"JSON Object"}],"index":2.7,"defaultExpressionType":"text","sensitive":false},"title":"Output Format","default":"text","type":"string"},"systemPrompt":{"title":"Instructions","buildship":{"sensitive":false,"defaultExpressionType":"text","index":0,"placeholder":"System default"},"description":"Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.","default":"","type":"string","properties":{}},"temperature":{"title":"Temperature","properties":{},"type":"number","description":"The temperature for the output","default":0.5,"buildship":{"sensitive":false,"defaultExpressionType":"text","index":2.5}},"conversationLimit":{"title":"Conversation Limit","default":10,"type":"number","properties":{},"buildship":{"index":2.4,"sensitive":false},"description":"Number of last messages to be fetched from the storage file."}},"type":"object","sections":{"section_993aceb2_d0d5_4766_b25e_b210912bf611":{"buildship":{"index":2,"collapseByDefault":true,"collapsed":true},"title":"Additional Settings","type":"section"}},"structure":[{"index":0,"parentId":null,"depth":0,"id":"systemPrompt"},{"depth":0,"parentId":null,"id":"userRequest","index":1},{"parentId":null,"children":[{"depth":1,"id":"model","index":0,"parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611"},{"parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611","index":1,"depth":1,"id":"sessionKey"},{"id":"conversationLimit","depth":1,"index":2,"parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611"},{"depth":1,"parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611","id":"temperature","index":4},{"id":"maxTokens","depth":1,"index":3,"parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611"},{"index":5,"depth":1,"id":"outputFormat","parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611"}],"index":2,"depth":0,"id":"section_993aceb2_d0d5_4766_b25e_b210912bf611"}]},"buildshipKey":true,"type":"script","integrations":[],"dependencies":{"fs":"0.0.2","openai":"4.76.0","path":"0.12.7"},"meta":{"icon":{"type":"URL","url":"https://storage.googleapis.com/buildship-app-us-central1-public/icons/diffbot.jpg"},"name":"Diffbot AI Chat","id":"keyless-diffbot-chat","description":"A keyless node to ask the Diffbot to help you integrate and research data on the web and answer questions - just type what you need in plain language."},"_libRef":{"src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/keyless-diffbot-chat/1.0.5/build.cjs","libType":"public","libNodeRefId":"@buildship/keyless-diffbot-chat","buildHash":"edd2695b50525e6b8e594760b67cc8655c6a66fdf375781a1ff9470ea071220e","isDirty":false,"version":"1.0.5","integrity":"v3:5ad644f9e810f69f876ec3151d2299f9"},"output":{"title":"Generated Text","buildship":{"index":0},"description":"Generated response by AI.","type":"string"},"label":"diffy founder research","_groupInfo":{"category":"AI Models","name":"Diffbot","iconUrl":"https://storage.googleapis.com/buildship-app-us-central1-public/icons/diffbot.jpg","uid":"diffbot","description":"Nodes for extracting and structuring web data using Diffbot's Knowledge Graph.","acceptsKey":true,"id":"diffbot"}}],"syi1rt":[{"script":"import OpenAI from \"openai\";\nimport fs from \"fs\";\nimport path from \"path\";\n\nconst getAccessToken = async () => {\n  const response = await fetch(\n    \"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n    { headers: { \"Metadata-Flavor\": \"Google\" } },\n  );\n  if (!response.ok) {\n    throw new Error(`Failed to obtain access token: ${response.statusText}`);\n  }\n  const data = await response.json();\n  return data.access_token;\n};\n\nexport default async function perplexityAIChatModel(\n  {\n    userRequest,\n    systemPrompt,\n    model,\n    temperature,\n    sessionKey,\n    conversationLimit,\n    maxTokens,\n    outputFormat,\n    kbIntegrationKey,\n  },\n  { logging, auth, workflow, node },\n) {\n  try {\n    const client =\n      kbIntegrationKey?.split(\";;\")[1] === \"credits\"\n        ? new OpenAI({\n            baseURL: \"https://proxy.buildship.run/llm/perplexity\",\n            apiKey: await getAccessToken(),\n          })\n        : new OpenAI({\n            apiKey: auth.getKey(),\n            baseURL: \"https://api.perplexity.ai\"\n          });\n    \n    let previousMessages = [];\n    const filePath =\n      process.env.BUCKET_FOLDER_PATH +\n      \"/nodes/openai-chat/store/\" +\n      sessionKey +\n      \".jsonl\";\n    \n    if (sessionKey && fs.existsSync(filePath)) {\n      const fileContent = fs.readFileSync(filePath, \"utf-8\");\n      const lines = fileContent.trim().split(\"\\n\").slice(-conversationLimit);\n      for (const line of lines) {\n        const { userRequest, assistantResponse } = JSON.parse(line);\n        previousMessages.push({ role: \"user\", content: userRequest });\n        previousMessages.push({\n          role: \"assistant\",\n          content: assistantResponse.content || assistantResponse,\n        });\n      }\n    }\n    \n    const jsonInstruction = \"##Output a valid JSON Object. Provide detailed answers with inline citations using markdown links. Example: [Source](https://example.com)##.\\n\";\n    \n    const messages = [\n      {\n        role: \"system\",\n        content: outputFormat === \"json_object\"\n          ? jsonInstruction + systemPrompt\n          : systemPrompt ?? \"Provide detailed answers with inline citations using markdown links. Example: [Source](https://example.com)\",\n      },\n      ...previousMessages,\n      { \n        role: \"user\", \n        content: userRequest || \"Default user prompt\"\n      },\n    ];\n    \n    messages.forEach(msg => {\n      if (typeof msg.content !== 'string') {\n        msg.content = JSON.stringify(msg.content);\n      }\n    });\n    \n    const response = await client.chat.completions.create(\n      {\n        model,\n        temperature,\n        messages,\n        max_tokens: maxTokens,\n        ...(outputFormat === \"json_object\" && {\n          response_format: { type: \"json_object\" },\n        }),\n      },\n      {\n        ...(kbIntegrationKey?.split(\";;\")[1] === \"credits\"\n          ? {\n              headers: {\n                \"x-buildship-workflow-id\": workflow?.id,\n                \"x-buildship-node-id\": node?.id,\n              },\n            }\n          : {}),\n      },\n    );\n    \n    const processedOutput = processResponse(response, outputFormat);\n    \n    if (sessionKey) {\n      const folderPath = path.dirname(filePath);\n      if (!fs.existsSync(folderPath)) {\n        fs.mkdirSync(folderPath, { recursive: true });\n      }\n      const dataToSave = { userRequest, assistantResponse: processedOutput };\n      fs.appendFileSync(filePath, JSON.stringify(dataToSave) + \"\\n\");\n    }\n    \n    return processedOutput;\n  } catch (e) {\n    console.error(\"Perplexity API Error:\", e);\n    throw new Error(`Perplexity API Error: ${e.message}`);\n  }\n}\n\n/**\n * Process the response from Perplexity AI API\n * @param {Object} response - The response from Perplexity AI\n * @param {String} outputFormat - The desired output format\n * @returns {Object} - Processed response with citations, content, and reasoning\n */\nfunction processResponse(response, outputFormat) {\n  // Extract content from the message\n  const messageContent = response.choices[0].message.content || \"\";\n  \n  // Extract citations if they exist in the response\n  const citations = response.citations || [];\n  \n  // Extract reasoning if it exists within <think>...</think> tags\n  let reasoning = \"\";\n  const thinkMatch = messageContent.match(/<think>([\\s\\S]*?)<\\/think>/);\n  if (thinkMatch && thinkMatch[1]) {\n    reasoning = thinkMatch[1].trim();\n  }\n  \n  // Extract the actual content (everything after the </think> tag or the whole content if no think tag)\n  let content = messageContent;\n  if (thinkMatch) {\n    content = messageContent.replace(/<think>[\\s\\S]*?<\\/think>\\s*/, \"\").trim();\n  }\n  \n  // Handle citation references in content (e.g., [1], [2], etc.)\n  // Remove citation references from the content\n  content = content.replace(/\\[\\d+\\]/g, \"\").trim();\n  \n  // Parse JSON content if needed\n  let parsedContent = content;\n  if (outputFormat === \"json_object\") {\n    try {\n      parsedContent = JSON.parse(content || \"{}\");\n    } catch (e) {\n      console.warn(\"Failed to parse JSON response:\", e.message);\n      parsedContent = { error: \"Invalid JSON response\", raw: content };\n    }\n  }\n  \n  // Prepare the final output based on the desired format\n  const result = {\n    citations: citations.reduce((acc, url, index) => {\n      acc[index + 1] = url;\n      return acc;\n    }, {}),\n    content: outputFormat === \"json_object\" ? parsedContent : content,\n    reasoning: reasoning || undefined\n  };\n  \n  // If reasoning is empty, don't include it in the output\n  if (!reasoning) {\n    delete result.reasoning;\n  }\n  \n  return result;\n}","_libRef":{"src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/keyless-perplexity-chat/5.0.7/build.cjs","version":"5.0.7","isDirty":false,"integrity":"v3:a72fd1719ea3befc10f0bf3b99f8ec9e","libNodeRefId":"@buildship/keyless-perplexity-chat","libType":"public","buildHash":"4d5fc90ac1e91cd6276b572495ccde63ac5e63efb3eda8d42715590917241e2c"},"meta":{"description":"A keyless node which sends a question to Perplexity's AI models and generates a response for the given chat conversation.","icon":{"type":"URL","url":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fperplexity.png?alt=media&token=c2b4b546-a17f-4866-8635-73377b79bca4"},"id":"keyless-perplexity-chat","name":"Perplexity AI Chat"},"integrations":[],"type":"script","dependencies":{"openai":"4.87.4","fs":"0.0.2","path":"0.12.7"},"output":{"type":"string","buildship":{},"description":"The response text or JSON object.","title":"Response"},"id":"7111a5bf-8742-4992-b31c-97bcfb390b79","_groupInfo":{"name":"Perplexity AI","category":"AI Models","keyDescription":"Perplexity AI API Key. Generate an API key through the [Perplexity Account Settings Page](https://www.perplexity.ai/settings).","id":"perplexity","longDescription":"Integrate Perplexity AI's advanced language model with BuildShip to enhance your AI-driven workflows. Utilize predefined nodes to perform rapid and efficient natural language processing tasks, enabling capabilities such as text generation, summarization, and contextual analysis effortlessly within your applications.","iconUrl":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fperplexity.png?alt=media&token=c2b4b546-a17f-4866-8635-73377b79bca4","uid":"perplexity","acceptsKey":true,"description":"Nodes to leverage Perplexity AI's blazingly fast LLM inference."},"inputs":{"required":["outputFormat","userRequest","model"],"properties":{"output_format":{"default":"text","buildship":{"options":[{"value":"text","label":"Text"},{"label":"JSON Object","value":"json_object"}],"sensitive":false,"index":2.7,"defaultExpressionType":"text"},"enum":["text","json_object"],"properties":{},"type":"string","description":"The format of the output","title":"Output Format"},"sessionKey":{"default":"","title":"Session Key","properties":{},"description":"Unique key to identify the conversation session for history retrieval.","type":"string","buildship":{"defaultExpressionType":"text","index":2.3,"sensitive":false,"placeholder":"session-xyz-123"}},"userRequest":{"properties":{},"title":"Prompt","buildship":{"index":1,"defaultExpressionType":"text","sensitive":false},"type":"string","description":"The user's message to the chat.","default":"Generate 5 tools for AI agents to call via an API that handle specific business tasks, with a one-sentence summary of inputs, logic flows (leveraging LLMs, image, or data / knowledge base analysis), external connections needed, and expected outputs."},"temperature":{"buildship":{"defaultExpressionType":"text","sensitive":false,"index":2.5},"type":"number","description":"The temperature for the output","properties":{},"default":0.5,"title":"Temperature"},"conversationLimit":{"default":2,"buildship":{"sensitive":false,"index":2.4,"defaultExpressionType":"text"},"title":"Conversation Limit","properties":{},"type":"number","description":"The number of the last messages to be fetched from the storage file. Keep this low, as Perplexity has low input tokens."},"maxTokens":{"title":"Max Tokens","properties":{},"description":"The maximum number of tokens to generate in the response","buildship":{"defaultExpressionType":"text","index":2.6,"sensitive":false},"type":"number","default":1600},"systemPrompt":{"properties":{},"description":"The system's prompt message.","title":"Instructions","default":"","type":"string","buildship":{"placeholder":"System default","defaultExpressionType":"text","sensitive":false,"index":0}},"model":{"properties":{},"enum":["sonar-deep-research","sonar-reasoning-pro","sonar-reasoning","sonar-pro","sonar","llama-3.1-sonar-small-128k-online","r-1-1776"],"default":"sonar-pro","title":"Model","pattern":"","type":"string","buildship":{"sensitive":false,"options":[{"label":"sonar-deep-research","value":"sonar-deep-research"},{"value":"sonar-reasoning-pro","label":"sonar-reasoning-pro"},{"value":"sonar-reasoning","label":"sonar-reasoning"},{"value":"sonar-pro","label":"sonar-pro"},{"label":"sonar","value":"sonar"},{"label":"llama-3.1-sonar-small-128k-online","value":"llama-3.1-sonar-small-128k-online"},{"value":"r1-1776","label":"r1-1776"}],"defaultExpressionType":"text","index":2.2},"description":"Select a Perplexity AI model."}},"sections":{"section_a1671ee7_0f0a_4eac_9307_4337093fff82":{"buildship":{"collapseByDefault":true,"index":2},"type":"section","title":"Advanced Settings"}},"type":"object","structure":[{"index":0,"id":"systemPrompt","depth":0,"parentId":null},{"parentId":null,"id":"userRequest","depth":0,"index":1},{"index":2,"id":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","depth":0,"children":[{"index":0,"id":"model","depth":1,"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82"},{"depth":1,"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","id":"sessionKey","index":1},{"id":"conversationLimit","depth":1,"index":2,"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82"},{"index":3,"id":"temperature","parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","depth":1},{"depth":1,"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","index":4,"id":"maxTokens"},{"id":"output_format","depth":1,"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","index":5}],"parentId":null}]},"buildshipKey":true,"label":"p founder research"}]},"description":"The Parallel node allows you to run multiple nodes simultaneously. It is useful for executing independent logic in parallel, saving valuable time in your workflow. \n\nKey Features:  \n- Processes input elements concurrently, unlike series processing, which runs sequentially.  \n- Useful for tasks like making multiple API calls at once.  \n- Concurrency limits depend on your BuildShip plan, please check the [pricing page](https://buildship.com/pricing) to see the maximum concurrency limit for your plan. \n\nLearn more about the Parallel node: [Docs](https://docs.buildship.com/core-nodes/parallel)"}],"label":"Loop","id":"80488f56-ebe0-4148-a119-366243385f89","type":"loop","description":"The Loop node processes each element in the input data sequentially, applying specified actions. Ideal for step-by-step transformations and ordered execution. \n\nLearn more about the Loop node: [Docs](https://docs.buildship.com/core-nodes/loop)"},{"meta":{"id":"keyless-claude-chat","name":"Anthropic Claude AI Chat","description":"A keyless node that uses Anthropic Claude to generate text or JSON based on given prompts and system context.","icon":{"url":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fanthropic.png?alt=media&token=ec0eb8dc-f0d4-4f97-a144-023f1aa8118e","type":"URL"}},"integrations":[],"type":"script","inputs":{"structure":[{"depth":0,"id":"systemPrompt","index":0,"parentId":null},{"index":1,"parentId":null,"id":"userPrompt","depth":0},{"index":2,"children":[{"parentId":"section_b2e281ec_5489_4407_80b5_233e2ef6fcc1","depth":1,"id":"modelId","index":0},{"depth":1,"parentId":"section_b2e281ec_5489_4407_80b5_233e2ef6fcc1","index":1,"id":"sessionKey"},{"index":2,"depth":1,"id":"conversationLimit","parentId":"section_b2e281ec_5489_4407_80b5_233e2ef6fcc1"},{"parentId":"section_b2e281ec_5489_4407_80b5_233e2ef6fcc1","id":"temperature","index":4,"depth":1},{"depth":1,"id":"maxTokens","index":3,"parentId":"section_b2e281ec_5489_4407_80b5_233e2ef6fcc1"}],"id":"section_b2e281ec_5489_4407_80b5_233e2ef6fcc1","parentId":null,"depth":0}],"sections":{"section_b2e281ec_5489_4407_80b5_233e2ef6fcc1":{"type":"section","title":"Additional Settings","buildship":{"collapsed":false,"collapseByDefault":true,"index":2}}},"properties":{"systemPrompt":{"type":"string","description":"The system prompt describing the task for Claude-3.\n\n**SAMPLE INPUT:**\n```\nYour task is to generate personalized recipe ideas based on the user's input of available ingredients and dietary preferences. Use this information to suggest a variety of creative and delicious recipes that can be made using the given ingredients while accommodating the user's dietary needs, if any are mentioned. For each recipe, provide a brief description, a list of required ingredients, and a simple set of instructions. Ensure that the recipes are easy to follow, nutritious, and can be prepared with minimal additional ingredients or equipment.\n```","pattern":"","default":"","title":"Instructions","buildship":{"placeholder":"System default","index":0,"sensitive":false,"defaultExpressionType":"text"},"properties":{}},"maxTokens":{"description":"The maximum number of tokens to be reserved for the generated output.","title":"Max Tokens","pattern":"","buildship":{"index":2.6,"defaultExpressionType":"text","sensitive":false},"properties":{},"default":1600,"type":"number"},"sessionKey":{"title":"Session Key","type":"string","buildship":{"index":2.3,"defaultExpressionType":"text","placeholder":"session-xyz-123","sensitive":false},"description":"A key to identify and save the conversation session.","properties":{}},"conversationLimit":{"properties":{},"buildship":{"sensitive":false,"defaultExpressionType":"text","index":2.4},"type":"number","description":"Number of last messages to be fetched from the storage file.","title":"Conversation Limit","default":10},"modelId":{"buildship":{"sensitive":false,"options":[{"label":"Claude 3.7 Sonnet","value":"claude-3-7-sonnet-20250219"},{"value":"claude-3-5-haiku-20241022","label":"Claude 3.5 Haiku"},{"label":"Claude 3.5 Sonnet","value":"claude-3-5-sonnet-20240620"},{"label":"Claude 3 Haiku","value":"claude-3-haiku-20240307"},{"value":"claude-3-opus-20240229","label":"Claude 3 Opus"}],"defaultExpressionType":"text","index":2.2},"properties":{},"default":"claude-3-7-sonnet-20250219","enum":["claude-3-7-sonnet-20250219","claude-3-5-haiku-20241022","claude-3-5-sonnet-20240620","claude-3-haiku-20240307","claude-3-opus-20240229"],"description":"The Claude Family models to choose from for text generation. [Comparison Table](https://docs.anthropic.com/claude/docs/models-overview#model-comparison).","title":"Model","pattern":"","type":"string"},"temperature":{"type":"number","default":0.5,"properties":{},"title":"Temperature","description":"The temperature to control the randomness of the response. (Range: 0-1)","buildship":{"index":2.5,"defaultExpressionType":"text","sensitive":false},"pattern":""},"userPrompt":{"buildship":{"sensitive":false,"defaultExpressionType":"text","index":1},"pattern":"","title":"Prompt","default":"Generate 5 tools for AI agents to call via an API that handle specific business tasks, with a one-sentence summary of inputs, logic flows (leveraging LLMs, image, or data / knowledge base analysis), external connections needed, and expected outputs.","description":"The user prompt to be processed by Claude-3.\n","properties":{},"type":"string"}},"type":"object","required":["apiKey","userPrompt","modelId"]},"label":"product founder fit report","buildshipKey":true,"id":"ab3cd994-21ff-46d8-b06a-8cdc899925ef","dependencies":{"path":"0.12.7","openai":"4.86.1","fs":"0.0.2"},"output":{"buildship":{"index":0},"type":"string","title":"Response"},"_libRef":{"integrity":"v3:063001c7455f6d1a341f2c5cfab6bee1","libNodeRefId":"@buildship/keyless-claude-chat","isDirty":false,"libType":"public","buildHash":"62e4d038781767fd386edefcc97c686435697547980605764ba6b1c2b534891c","src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/keyless-claude-chat/5.0.11/build.cjs","version":"5.0.11"},"_groupInfo":{"iconUrl":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fanthropic.png?alt=media&token=ec0eb8dc-f0d4-4f97-a144-023f1aa8118e","acceptsKey":true,"keyDescription":"Your Anthropic [Claude API](https://console.anthropic.com/settings/keys) key for authentication","id":"anthropic","description":"Nodes for interacting with and using Anthropic's Claude AI Models.","name":"Anthropic","longDescription":"Nodes for interacting with Anthropic's Claude AI Models enable easy integration with AI functionalities such as text generation, natural language understanding, and conversational agents. Leverage the advanced capabilities of Claude to build intelligent applications, automate tasks, and enhance user interactions with minimal configuration effort.","uid":"anthropic","category":"AI Models"},"script":"import OpenAI from \"openai\";\nimport fs from \"fs\";\nimport path from \"path\";\n\nconst getAccessToken = async () => {\n  const response = await fetch(\n    \"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n    { headers: { \"Metadata-Flavor\": \"Google\" } },\n  );\n  if (!response.ok) {\n    throw new Error(`Failed to obtain access token: ${response.statusText}`);\n  }\n  const data = await response.json();\n  return data.access_token;\n};\n\nexport default async function generateTextWithClaude3({\n    systemPrompt,\n    userPrompt,\n    modelId,\n    maxTokens,\n    temperature,\n    kbIntegrationKey,\n    sessionKey,\n    conversationLimit\n}: NodeInputs, {auth, node, workflow}: NodeScriptOptions) : NodeOutput  {\n\n  const client =\n      kbIntegrationKey?.split(\";;\")[1] === \"credits\"\n        ? new OpenAI({\n            baseURL: \"https://proxy.buildship.run/llm/anthropic\",\n            apiKey: await getAccessToken(),\n          })\n        : new OpenAI({\n            apiKey: auth.getKey(),\n          });\n\n  let previousMessages = [];\n  const filePath = process.env.BUCKET_FOLDER_PATH + '/nodes/openai-chat/store/' + sessionKey + '.jsonl'\n  if (sessionKey && fs.existsSync(filePath)) {\n    const fileContent = fs.readFileSync(filePath, \"utf-8\");\n    const lines = fileContent.trim().split(\"\\n\");\n    for (const line of lines.slice(-conversationLimit * 2)) { // Each message has two lines (user and assistant)\n      const { userRequest, assistantResponse } = JSON.parse(line);\n      previousMessages.push({ role: \"user\", content: userRequest });\n      previousMessages.push({ role: \"assistant\", content: assistantResponse });\n    }\n  }\n\n  const response = await client.chat.completions.create({\n    model: modelId,\n    max_tokens: parseInt(maxTokens),\n    temperature: parseInt(temperature),\n    messages: [{ role: \"system\", content: systemPrompt ?? \"System Default\" }, ...previousMessages, { role: \"user\", content: userPrompt }],\n  },{\n    ...(kbIntegrationKey?.split(\";;\")[1] === \"credits\"\n      ? {\n          headers: {\n            \"x-buildship-workflow-id\": workflow?.id,\n            \"x-buildship-node-id\": node?.id,\n          },\n        }\n      : {}),\n  });\n\n  const output = response.choices[0].message.content;\n\n  if (sessionKey) {\n    const folderPath = path.dirname(filePath);\n    if (!fs.existsSync(folderPath)) {\n      fs.mkdirSync(folderPath, { recursive: true });\n    }\n    const dataToSave = { userRequest: userPrompt, assistantResponse: output };\n    fs.appendFileSync(filePath, JSON.stringify(dataToSave) + \"\\n\");\n  }\n\n  return output;\n}\n"}],"5ga8o":[{"inputs":{"properties":{"systemPrompt":{"description":"Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.","properties":{},"buildship":{"placeholder":"System default","index":0,"defaultExpressionType":"text","sensitive":false},"title":"Instructions","default":"","type":"string"},"outputFormat":{"type":"string","title":"Output Format","properties":{},"default":"text","enum":["text","json_object"],"buildship":{"sensitive":false,"index":2.7,"defaultExpressionType":"text","options":[{"label":"Text","value":"text"},{"label":"JSON Object","value":"json_object"}]},"description":"Select the format of the output."},"userRequest":{"description":"The prompt to send to the assistant as user message.","type":"string","default":"Generate 5 tools for AI agents to call via an API that handle specific business tasks, with a one-sentence summary of inputs, logic flows (leveraging LLMs, image, or data / knowledge base analysis), external connections needed, and expected outputs.","buildship":{"defaultExpressionType":"text","sensitive":false,"index":1},"properties":{},"title":"Prompt"},"conversationLimit":{"default":10,"description":"Number of last messages to be fetched from the storage file.","properties":{},"title":"Conversation Limit","type":"number","buildship":{"sensitive":false,"index":2.4}},"temperature":{"properties":{},"title":"Temperature","buildship":{"sensitive":false,"index":2.5,"defaultExpressionType":"text"},"description":"The temperature for the output","type":"number","default":0.5},"maxTokens":{"properties":{},"buildship":{"defaultExpressionType":"text","index":2.6,"sensitive":false},"title":"Max Tokens","default":1600,"type":"number"},"sessionKey":{"title":"Session Key","buildship":{"index":2.3,"placeholder":"session-xyz-123","defaultExpressionType":"text","sensitive":false},"description":"Key to save and load conversation history.","properties":{},"default":"","type":"string"},"model":{"buildship":{"index":2.2,"sensitive":false,"defaultExpressionType":"text","options":[{"value":"diffbot-small-xl","label":"diffbot-small-xl"}]},"title":"Model","type":"string","properties":{},"default":"diffbot-small-xl","enum":["diffbot-small-xl"]}},"structure":[{"id":"systemPrompt","parentId":null,"index":0,"depth":0},{"parentId":null,"index":1,"depth":0,"id":"userRequest"},{"parentId":null,"index":2,"children":[{"index":0,"parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611","id":"model","depth":1},{"parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611","index":1,"depth":1,"id":"sessionKey"},{"depth":1,"index":2,"id":"conversationLimit","parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611"},{"depth":1,"id":"temperature","parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611","index":4},{"parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611","depth":1,"index":3,"id":"maxTokens"},{"parentId":"section_993aceb2_d0d5_4766_b25e_b210912bf611","index":5,"id":"outputFormat","depth":1}],"depth":0,"id":"section_993aceb2_d0d5_4766_b25e_b210912bf611"}],"type":"object","required":["userRequest","model"],"sections":{"section_993aceb2_d0d5_4766_b25e_b210912bf611":{"buildship":{"collapsed":true,"collapseByDefault":true,"index":2},"title":"Additional Settings","type":"section"}}},"_libRef":{"src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/keyless-diffbot-chat/1.0.5/build.cjs","libNodeRefId":"@buildship/keyless-diffbot-chat","buildHash":"edd2695b50525e6b8e594760b67cc8655c6a66fdf375781a1ff9470ea071220e","integrity":"v3:5ad644f9e810f69f876ec3151d2299f9","version":"1.0.5","libType":"public","isDirty":false},"buildshipKey":true,"label":"Diffbot funding data","script":"import OpenAI from \"openai\";\nimport fs from \"fs\";\nimport path from \"path\";\n\nconst getAccessToken = async () => {\n  const response = await fetch(\n    \"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n    {\n      headers: { \"Metadata-Flavor\": \"Google\" },\n    }\n  );\n  if (!response.ok) {\n    throw new Error(`Failed to obtain access token: ${response.statusText}`);\n  }\n  const data = await response.json();\n  return data.access_token;\n};\n\nexport default async (\n  {\n    userRequest,\n    systemPrompt,\n    model,\n    temperature,\n    sessionKey,\n    conversationLimit,\n    maxTokens,\n    outputFormat,\n    kbIntegrationKey,\n  },\n  { logging, workflow, node, auth }\n) => {\n  const openai = kbIntegrationKey?.split(\";;\")[1] === \"credits\" ?\n    new OpenAI({\n    baseURL: \"https://proxy.buildship.run/llm/diffbot\",\n    apiKey: await getAccessToken(),\n  }) : new OpenAI({\n    apiKey: auth.getKey(),\n  });\n\n  let previousMessages = [];\n  const filePath =\n    process.env.BUCKET_FOLDER_PATH +\n    \"/nodes/openai-chat/store/\" +\n    sessionKey +\n    \".jsonl\";\n  if (sessionKey && fs.existsSync(filePath)) {\n    const fileContent = fs.readFileSync(filePath, \"utf-8\");\n    const lines = fileContent.trim().split(\"\\n\").slice(-conversationLimit);\n    for (const line of lines) {\n      const { userRequest, assistantResponse } = JSON.parse(line);\n      previousMessages.push({ role: \"user\", content: userRequest });\n      previousMessages.push({ role: \"assistant\", content: assistantResponse });\n    }\n  }\n\n  const jsonInstruction = \"##Output a valid JSON Object##.\\n\";\n  const response = await openai.chat.completions.create(\n    {\n      model,\n      temperature,\n      max_tokens: maxTokens,\n      messages: [\n        {\n          role: \"system\",\n          content:\n            outputFormat === \"json_object\"\n              ? jsonInstruction + systemPrompt\n              : systemPrompt,\n        },\n        ...previousMessages,\n        { role: \"user\", content: userRequest },\n      ],\n      ...(outputFormat === \"json_object\" && {\n        response_format: { type: \"json_object\" },\n      }),\n    },\n    {\n      ...(kbIntegrationKey?.split(\";;\")[1] === \"credits\"\n        ? {\n            headers: {\n              \"x-buildship-workflow-id\": workflow?.id,\n              \"x-buildship-node-id\": node?.id,\n            },\n          }\n        : {}),\n    }\n  );\n\n  const output = response.choices[0].message.content;\n  if (sessionKey) {\n    const folderPath = path.dirname(filePath);\n    if (!fs.existsSync(folderPath)) {\n      fs.mkdirSync(folderPath, { recursive: true });\n    }\n    const dataToSave = { userRequest, assistantResponse: output };\n    fs.appendFileSync(filePath, JSON.stringify(dataToSave) + \"\\n\");\n  }\n  return output;\n};\n","id":"e921fb25-0390-467d-9352-8db3d52ed27a","type":"script","dependencies":{"fs":"0.0.2","path":"0.12.7","openai":"4.76.0"},"_groupInfo":{"iconUrl":"https://storage.googleapis.com/buildship-app-us-central1-public/icons/diffbot.jpg","name":"Diffbot","category":"AI Models","description":"Nodes for extracting and structuring web data using Diffbot's Knowledge Graph.","acceptsKey":true,"id":"diffbot","uid":"diffbot"},"integrations":[],"output":{"type":"string","description":"Generated response by AI.","title":"Generated Text","buildship":{"index":0}},"meta":{"icon":{"type":"URL","url":"https://storage.googleapis.com/buildship-app-us-central1-public/icons/diffbot.jpg"},"id":"keyless-diffbot-chat","name":"Diffbot AI Chat","description":"A keyless node to ask the Diffbot to help you integrate and research data on the web and answer questions - just type what you need in plain language."}}],"5ga8n":[{"inputs":{"type":"object","structure":[{"index":0,"id":"systemPrompt","parentId":null,"depth":0},{"parentId":null,"depth":0,"id":"userRequest","index":1},{"parentId":null,"children":[{"id":"model","index":0,"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","depth":1},{"id":"sessionKey","index":1,"depth":1,"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82"},{"index":2,"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","depth":1,"id":"conversationLimit"},{"id":"temperature","depth":1,"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","index":3},{"id":"maxTokens","parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","depth":1,"index":4},{"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","id":"output_format","depth":1,"index":5}],"id":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","index":2,"depth":0}],"properties":{"model":{"type":"string","default":"sonar-pro","pattern":"","buildship":{"index":2.2,"defaultExpressionType":"text","sensitive":false,"options":[{"value":"sonar-deep-research","label":"sonar-deep-research"},{"value":"sonar-reasoning-pro","label":"sonar-reasoning-pro"},{"value":"sonar-reasoning","label":"sonar-reasoning"},{"value":"sonar-pro","label":"sonar-pro"},{"value":"sonar","label":"sonar"},{"label":"llama-3.1-sonar-small-128k-online","value":"llama-3.1-sonar-small-128k-online"},{"value":"r1-1776","label":"r1-1776"}]},"enum":["sonar-deep-research","sonar-reasoning-pro","sonar-reasoning","sonar-pro","sonar","llama-3.1-sonar-small-128k-online","r-1-1776"],"properties":{},"title":"Model","description":"Select a Perplexity AI model."},"sessionKey":{"buildship":{"defaultExpressionType":"text","sensitive":false,"index":2.3,"placeholder":"session-xyz-123"},"description":"Unique key to identify the conversation session for history retrieval.","title":"Session Key","type":"string","properties":{},"default":""},"conversationLimit":{"title":"Conversation Limit","properties":{},"buildship":{"sensitive":false,"defaultExpressionType":"text","index":2.4},"type":"number","default":2,"description":"The number of the last messages to be fetched from the storage file. Keep this low, as Perplexity has low input tokens."},"maxTokens":{"properties":{},"buildship":{"sensitive":false,"defaultExpressionType":"text","index":2.6},"default":1600,"title":"Max Tokens","description":"The maximum number of tokens to generate in the response","type":"number"},"output_format":{"type":"string","buildship":{"defaultExpressionType":"text","index":2.7,"sensitive":false,"options":[{"label":"Text","value":"text"},{"value":"json_object","label":"JSON Object"}]},"description":"The format of the output","properties":{},"enum":["text","json_object"],"default":"text","title":"Output Format"},"userRequest":{"properties":{},"type":"string","title":"Prompt","buildship":{"index":1,"sensitive":false,"defaultExpressionType":"text"},"description":"The user's message to the chat.","default":"Generate 5 tools for AI agents to call via an API that handle specific business tasks, with a one-sentence summary of inputs, logic flows (leveraging LLMs, image, or data / knowledge base analysis), external connections needed, and expected outputs."},"systemPrompt":{"properties":{},"type":"string","buildship":{"index":0,"placeholder":"System default","defaultExpressionType":"text","sensitive":false},"default":"","title":"Instructions","description":"The system's prompt message."},"temperature":{"properties":{},"type":"number","title":"Temperature","default":0.5,"description":"The temperature for the output","buildship":{"index":2.5,"sensitive":false,"defaultExpressionType":"text"}}},"required":["outputFormat","userRequest","model"],"sections":{"section_a1671ee7_0f0a_4eac_9307_4337093fff82":{"title":"Advanced Settings","buildship":{"index":2,"collapseByDefault":true},"type":"section"}}},"integrations":[],"output":{"description":"The response text or JSON object.","title":"Response","buildship":{},"type":"string"},"id":"c7ff1f45-2560-4b9e-8c91-d8367530a60f","_libRef":{"integrity":"v3:a72fd1719ea3befc10f0bf3b99f8ec9e","libNodeRefId":"@buildship/keyless-perplexity-chat","isDirty":false,"buildHash":"4d5fc90ac1e91cd6276b572495ccde63ac5e63efb3eda8d42715590917241e2c","src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/keyless-perplexity-chat/5.0.7/build.cjs","version":"5.0.7","libType":"public"},"_groupInfo":{"category":"AI Models","acceptsKey":true,"description":"Nodes to leverage Perplexity AI's blazingly fast LLM inference.","longDescription":"Integrate Perplexity AI's advanced language model with BuildShip to enhance your AI-driven workflows. Utilize predefined nodes to perform rapid and efficient natural language processing tasks, enabling capabilities such as text generation, summarization, and contextual analysis effortlessly within your applications.","keyDescription":"Perplexity AI API Key. Generate an API key through the [Perplexity Account Settings Page](https://www.perplexity.ai/settings).","iconUrl":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fperplexity.png?alt=media&token=c2b4b546-a17f-4866-8635-73377b79bca4","uid":"perplexity","name":"Perplexity AI","id":"perplexity"},"meta":{"icon":{"url":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fperplexity.png?alt=media&token=c2b4b546-a17f-4866-8635-73377b79bca4","type":"URL"},"description":"A keyless node which sends a question to Perplexity's AI models and generates a response for the given chat conversation.","id":"keyless-perplexity-chat","name":"Perplexity AI Chat"},"buildshipKey":true,"type":"script","label":"Perplexity AI funding data","script":"import OpenAI from \"openai\";\nimport fs from \"fs\";\nimport path from \"path\";\n\nconst getAccessToken = async () => {\n  const response = await fetch(\n    \"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n    { headers: { \"Metadata-Flavor\": \"Google\" } },\n  );\n  if (!response.ok) {\n    throw new Error(`Failed to obtain access token: ${response.statusText}`);\n  }\n  const data = await response.json();\n  return data.access_token;\n};\n\nexport default async function perplexityAIChatModel(\n  {\n    userRequest,\n    systemPrompt,\n    model,\n    temperature,\n    sessionKey,\n    conversationLimit,\n    maxTokens,\n    outputFormat,\n    kbIntegrationKey,\n  },\n  { logging, auth, workflow, node },\n) {\n  try {\n    const client =\n      kbIntegrationKey?.split(\";;\")[1] === \"credits\"\n        ? new OpenAI({\n            baseURL: \"https://proxy.buildship.run/llm/perplexity\",\n            apiKey: await getAccessToken(),\n          })\n        : new OpenAI({\n            apiKey: auth.getKey(),\n            baseURL: \"https://api.perplexity.ai\"\n          });\n    \n    let previousMessages = [];\n    const filePath =\n      process.env.BUCKET_FOLDER_PATH +\n      \"/nodes/openai-chat/store/\" +\n      sessionKey +\n      \".jsonl\";\n    \n    if (sessionKey && fs.existsSync(filePath)) {\n      const fileContent = fs.readFileSync(filePath, \"utf-8\");\n      const lines = fileContent.trim().split(\"\\n\").slice(-conversationLimit);\n      for (const line of lines) {\n        const { userRequest, assistantResponse } = JSON.parse(line);\n        previousMessages.push({ role: \"user\", content: userRequest });\n        previousMessages.push({\n          role: \"assistant\",\n          content: assistantResponse.content || assistantResponse,\n        });\n      }\n    }\n    \n    const jsonInstruction = \"##Output a valid JSON Object. Provide detailed answers with inline citations using markdown links. Example: [Source](https://example.com)##.\\n\";\n    \n    const messages = [\n      {\n        role: \"system\",\n        content: outputFormat === \"json_object\"\n          ? jsonInstruction + systemPrompt\n          : systemPrompt ?? \"Provide detailed answers with inline citations using markdown links. Example: [Source](https://example.com)\",\n      },\n      ...previousMessages,\n      { \n        role: \"user\", \n        content: userRequest || \"Default user prompt\"\n      },\n    ];\n    \n    messages.forEach(msg => {\n      if (typeof msg.content !== 'string') {\n        msg.content = JSON.stringify(msg.content);\n      }\n    });\n    \n    const response = await client.chat.completions.create(\n      {\n        model,\n        temperature,\n        messages,\n        max_tokens: maxTokens,\n        ...(outputFormat === \"json_object\" && {\n          response_format: { type: \"json_object\" },\n        }),\n      },\n      {\n        ...(kbIntegrationKey?.split(\";;\")[1] === \"credits\"\n          ? {\n              headers: {\n                \"x-buildship-workflow-id\": workflow?.id,\n                \"x-buildship-node-id\": node?.id,\n              },\n            }\n          : {}),\n      },\n    );\n    \n    const processedOutput = processResponse(response, outputFormat);\n    \n    if (sessionKey) {\n      const folderPath = path.dirname(filePath);\n      if (!fs.existsSync(folderPath)) {\n        fs.mkdirSync(folderPath, { recursive: true });\n      }\n      const dataToSave = { userRequest, assistantResponse: processedOutput };\n      fs.appendFileSync(filePath, JSON.stringify(dataToSave) + \"\\n\");\n    }\n    \n    return processedOutput;\n  } catch (e) {\n    console.error(\"Perplexity API Error:\", e);\n    throw new Error(`Perplexity API Error: ${e.message}`);\n  }\n}\n\n/**\n * Process the response from Perplexity AI API\n * @param {Object} response - The response from Perplexity AI\n * @param {String} outputFormat - The desired output format\n * @returns {Object} - Processed response with citations, content, and reasoning\n */\nfunction processResponse(response, outputFormat) {\n  // Extract content from the message\n  const messageContent = response.choices[0].message.content || \"\";\n  \n  // Extract citations if they exist in the response\n  const citations = response.citations || [];\n  \n  // Extract reasoning if it exists within <think>...</think> tags\n  let reasoning = \"\";\n  const thinkMatch = messageContent.match(/<think>([\\s\\S]*?)<\\/think>/);\n  if (thinkMatch && thinkMatch[1]) {\n    reasoning = thinkMatch[1].trim();\n  }\n  \n  // Extract the actual content (everything after the </think> tag or the whole content if no think tag)\n  let content = messageContent;\n  if (thinkMatch) {\n    content = messageContent.replace(/<think>[\\s\\S]*?<\\/think>\\s*/, \"\").trim();\n  }\n  \n  // Handle citation references in content (e.g., [1], [2], etc.)\n  // Remove citation references from the content\n  content = content.replace(/\\[\\d+\\]/g, \"\").trim();\n  \n  // Parse JSON content if needed\n  let parsedContent = content;\n  if (outputFormat === \"json_object\") {\n    try {\n      parsedContent = JSON.parse(content || \"{}\");\n    } catch (e) {\n      console.warn(\"Failed to parse JSON response:\", e.message);\n      parsedContent = { error: \"Invalid JSON response\", raw: content };\n    }\n  }\n  \n  // Prepare the final output based on the desired format\n  const result = {\n    citations: citations.reduce((acc, url, index) => {\n      acc[index + 1] = url;\n      return acc;\n    }, {}),\n    content: outputFormat === \"json_object\" ? parsedContent : content,\n    reasoning: reasoning || undefined\n  };\n  \n  // If reasoning is empty, don't include it in the output\n  if (!reasoning) {\n    delete result.reasoning;\n  }\n  \n  return result;\n}","dependencies":{"path":"0.12.7","fs":"0.0.2","openai":"4.87.4"}}]},"description":"The Parallel node allows you to run multiple nodes simultaneously. It is useful for executing independent logic in parallel, saving valuable time in your workflow. \n\nKey Features:  \n- Processes input elements concurrently, unlike series processing, which runs sequentially.  \n- Useful for tasks like making multiple API calls at once.  \n- Concurrency limits depend on your BuildShip plan, please check the [pricing page](https://buildship.com/pricing) to see the maximum concurrency limit for your plan. \n\nLearn more about the Parallel node: [Docs](https://docs.buildship.com/core-nodes/parallel)","id":"5195fbc2-557d-4f62-baf6-251b690fea9f","label":"researching","type":"parallel"},{"type":"script","integrations":[],"_groupInfo":{"iconUrl":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fopenai.png?alt=media&token=9c513dd1-e2d4-47d2-8e3c-3a1a6ebf03e3","acceptsKey":true,"details":null,"category":"AI Models","longDescription":"BuildShip allows you to effortlessly integrate OpenAI models into your workflows, enabling the use of advanced machine learning capabilities for text generation, translation, and more. Streamline processes by utilizing AI-powered models to enhance automation, decision-making, and content generation in a seamless and efficient manner.","icon":null,"keyDescription":"Add your OpenAI API Key. Get it from your [OpenAI account](https://platform.openai.com/account/api-keys)","uid":"openai","description":"OpenAI Models","name":"OpenAI","id":"ZBwcODUEhzNMxYxpN1O8"},"meta":{"description":"A keyless node that generates perfectly structured JSON using OpenAI's Structured Outputs, ensuring strict adherence to a provided schema.","id":"openai-json-schema-generator","icon":{"type":"URL","url":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fopenai.png?alt=media&token=9c513dd1-e2d4-47d2-8e3c-3a1a6ebf03e3&_gl=1*b90bgk*_ga*MjAxOTYxMjk5OS4xNjk0NTIzMjQ2*_ga_CW55HF8NVT*MTY5NjQwMzEyMy4yNS4xLjE2OTY0MDMxNDQuMzkuMC4w"},"name":"JSON Generator"},"id":"bdcef193-9e69-4d5f-808d-beafc886fd86","buildshipKey":true,"script":"import OpenAI from \"openai\";\n\nconst getAccessToken = async () => {\n  const response = await fetch(\n    \"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n    { headers: { \"Metadata-Flavor\": \"Google\" } }\n  );\n  if (!response.ok) {\n    throw new Error(`Failed to obtain access token: ${response.statusText}`);\n  }\n  const data: any = await response.json();\n  return data?.access_token;\n};\n\nexport default async function openaiGptTextGenerator(\n  {\n    userPrompt,\n    systemPrompt,\n    maxTokens,\n    temperature,\n    model,\n    response_schema,\n    kbIntegrationKey,\n  }: NodeInputs & { kbIntegrationKey: string },\n  { auth, workflow, node }: NodeScriptOptions\n): NodeOutput {\n  const hasCredits = kbIntegrationKey?.split(\";;\")[1] === \"credits\";\n  const apiKey = hasCredits ? await getAccessToken() : auth.getKey();\n\n  if (!apiKey) {\n    throw new Error(\n      \"An integration key is required for this node to function, but no key was selected. Please select one from the node's toolbar.\"\n    );\n  }\n\n  const client = new OpenAI({\n    apiKey,\n    ...(hasCredits && { baseURL: \"https://proxy.buildship.run/llm/openai\" }),\n  });\n\n\n  const response = await client.responses.create(\n    {\n      model,\n      input: [\n        {\n          role: \"system\",\n          content: systemPrompt,\n        },\n        {\n          role: \"user\",\n          content: userPrompt,\n        },\n      ],\n      text: {\n        format: transformResponseSchema(response_schema),\n      },\n      max_output_tokens: maxTokens,\n      temperature,\n    },\n    hasCredits\n      ? {\n          headers: {\n            \"x-buildship-workflow-id\": workflow?.id,\n            \"x-buildship-node-id\": node?.id,\n          },\n        }\n      : undefined\n  );\n\n  try {\n    return JSON.parse(response.output_text);\n  } catch (e) {\n    throw new Error(\"Failed to parse response output_text as JSON.\");\n  }\n}\n\n\nfunction transformResponseSchema(response_schema: any) {\n  if (!response_schema?.json_schema?.schema) {\n    throw new Error(\"Invalid or missing response_schema format.\");\n  }\n\n  const UNSUPPORTED_BY_TYPE: Record<string, string[]> = {\n    string: [\"minLength\", \"maxLength\", \"pattern\", \"format\"],\n    number: [\"minimum\", \"maximum\", \"multipleOf\"],\n    object: [\n      \"patternProperties\", \"unevaluatedProperties\", \"propertyNames\",\n      \"minProperties\", \"maxProperties\"\n    ],\n    array: [\n      \"unevaluatedItems\", \"contains\", \"minContains\", \"maxContains\",\n      \"minItems\", \"maxItems\", \"uniqueItems\"\n    ],\n  };\n\n  const clean = (schema: any, inProps = false): any => {\n    if (Array.isArray(schema)) return schema.map((s) => clean(s, inProps));\n    if (typeof schema !== \"object\" || schema === null) return schema;\n\n    const type = schema.type;\n    const unsupported = inProps ? [] : (UNSUPPORTED_BY_TYPE[type] || []);\n    \n    return Object.fromEntries(\n      Object.entries(schema).map(([k, v]) => {\n        if (unsupported.includes(k)) return null;\n        const nested = k === \"properties\" ? clean(v, true) : clean(v, false);\n        return [k, nested];\n      }).filter(Boolean)\n    );\n  };\n\n  return {\n    type: \"json_schema\",\n    name: response_schema.json_schema.name || \"response\",\n    strict: true,\n    schema: clean(response_schema.json_schema.schema),\n  };\n}\n","_libRef":{"isDirty":false,"integrity":"v3:b0f8e77b632793a3ae59c684f8258821","version":"2.1.11","buildHash":"2d4824f0e396200f8e154ff90d9af6879d4a8bd750b16fda5f95861c7a72ddca","libNodeRefId":"@buildship/openai-json-schema-generator","libType":"public","src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/openai-json-schema-generator/2.1.11/build.cjs"},"output":{"title":"Generated Text","properties":{},"type":"object","description":"The text generated by the OpenAI GPT API","buildship":{}},"dependencies":{"openai":"4.95.0"},"inputs":{"properties":{"systemPrompt":{"description":"The system prompt to generate JSON from.\n\n**When using this node, always instruct the model to produce JSON using the provided Schema.**\n\n**SAMPLE PROMPT**:\n```\nYou are a helpful math tutor. Only use the schema for math responses.\n```","type":"string","properties":{},"default":"Convert the input text into JSON following the schema exactly.","pattern":"","title":"Instructions","buildship":{"index":0,"sensitive":false,"placeholder":""}},"model":{"description":"The OpenAI Model to use for performing the JSON Generation.","title":"Model","enum":["gpt-4.1","gpt-4o-mini","gpt-4o"],"pattern":"","type":"string","buildship":{"index":3.4,"options":[{"value":"gpt-4.1","label":"gpt-4.1"},{"label":"gpt-4o-mini","value":"gpt-4o-mini"},{"value":"gpt-4o","label":"gpt-4o"}],"sensitive":false,"defaultExpressionType":"text"},"default":"gpt-4o-2024-08-06","properties":{}},"maxTokens":{"default":800,"description":"The maximum length (in tokens) of the generated JSON.","title":"Max Tokens","type":"number","pattern":"","buildship":{"sensitive":false,"index":3.2}},"temperature":{"properties":{},"pattern":"","description":"As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions.\n\n**RANGE: `0 to 1`**","buildship":{"sensitive":false,"index":3.3},"type":"number","title":"Temperature","default":0.1},"userPrompt":{"pattern":"","title":"Input","default":"The weather today is sunny with a temperature of 75 degrees.","properties":{},"buildship":{"index":1,"sensitive":false,"placeholder":"Your Unstructured Text"},"type":"string","description":"The user prompt to generate JSON from."},"response_schema":{"pattern":"","default":{"type":"schema","_$expression_":"","_$schema_":[{"required":true,"name":"weather","type":"string"},{"name":"temperature","type":"number","required":true},{"name":"description","type":"string","required":true},{"type":"boolean","required":true,"name":"isRaining"}]},"title":"Schema","description":"The response schema can be created using the Schema Builder.\n\nIt can also be created as a plain object in the JavaScript editor and it should be in a standard JSON Schema format.\n\n```\n{\n  \"type\": \"json_schema\",\n  \"json_schema\": {\n    \"name\": \"response\",\n    \"strict\": true,\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {},\n      \"required\": [],\n      \"additionalProperties\": false,\n      \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    },\n  },\n}\n```\n","properties":{},"buildship":{"defaultExpressionType":"schema","sensitive":false,"index":2},"type":"object"}},"sections":{"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982":{"title":"Advanced","type":"section","buildship":{"index":3,"collapsed":true}}},"required":["apiKey","systemPrompt","userPrompt","response_schema","model"],"type":"object","structure":[{"parentId":null,"index":0,"depth":0,"id":"systemPrompt"},{"index":1,"parentId":null,"depth":0,"id":"userPrompt"},{"depth":0,"parentId":null,"index":2,"id":"response_schema"},{"parentId":null,"id":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982","index":3,"children":[{"id":"maxTokens","index":0,"depth":1,"parentId":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982"},{"index":1,"parentId":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982","id":"temperature","depth":1},{"depth":1,"id":"model","parentId":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982","index":2}],"depth":0}]},"label":"funding data"},{"id":"25c02936-87a1-42eb-8d31-039e12e7ec38","label":"Competitor Summary","meta":{"id":"keyless-perplexity-chat","name":"Perplexity AI Chat","icon":{"type":"URL","url":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fperplexity.png?alt=media&token=c2b4b546-a17f-4866-8635-73377b79bca4"},"description":"A keyless node which sends a question to Perplexity's AI models and generates a response for the given chat conversation."},"integrations":[],"script":"import OpenAI from \"openai\";\nimport fs from \"fs\";\nimport path from \"path\";\n\nconst getAccessToken = async () => {\n  const response = await fetch(\n    \"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n    { headers: { \"Metadata-Flavor\": \"Google\" } },\n  );\n  if (!response.ok) {\n    throw new Error(`Failed to obtain access token: ${response.statusText}`);\n  }\n  const data = await response.json();\n  return data.access_token;\n};\n\nexport default async function perplexityAIChatModel(\n  {\n    userRequest,\n    systemPrompt,\n    model,\n    temperature,\n    sessionKey,\n    conversationLimit,\n    maxTokens,\n    outputFormat,\n    kbIntegrationKey,\n  },\n  { logging, auth, workflow, node },\n) {\n  try {\n    const client =\n      kbIntegrationKey?.split(\";;\")[1] === \"credits\"\n        ? new OpenAI({\n            baseURL: \"https://proxy.buildship.run/llm/perplexity\",\n            apiKey: await getAccessToken(),\n          })\n        : new OpenAI({\n            apiKey: auth.getKey(),\n            baseURL: \"https://api.perplexity.ai\"\n          });\n    \n    let previousMessages = [];\n    const filePath =\n      process.env.BUCKET_FOLDER_PATH +\n      \"/nodes/openai-chat/store/\" +\n      sessionKey +\n      \".jsonl\";\n    \n    if (sessionKey && fs.existsSync(filePath)) {\n      const fileContent = fs.readFileSync(filePath, \"utf-8\");\n      const lines = fileContent.trim().split(\"\\n\").slice(-conversationLimit);\n      for (const line of lines) {\n        const { userRequest, assistantResponse } = JSON.parse(line);\n        previousMessages.push({ role: \"user\", content: userRequest });\n        previousMessages.push({\n          role: \"assistant\",\n          content: assistantResponse.content || assistantResponse,\n        });\n      }\n    }\n    \n    const jsonInstruction = \"##Output a valid JSON Object. Provide detailed answers with inline citations using markdown links. Example: [Source](https://example.com)##.\\n\";\n    \n    const messages = [\n      {\n        role: \"system\",\n        content: outputFormat === \"json_object\"\n          ? jsonInstruction + systemPrompt\n          : systemPrompt ?? \"Provide detailed answers with inline citations using markdown links. Example: [Source](https://example.com)\",\n      },\n      ...previousMessages,\n      { \n        role: \"user\", \n        content: userRequest || \"Default user prompt\"\n      },\n    ];\n    \n    messages.forEach(msg => {\n      if (typeof msg.content !== 'string') {\n        msg.content = JSON.stringify(msg.content);\n      }\n    });\n    \n    const response = await client.chat.completions.create(\n      {\n        model,\n        temperature,\n        messages,\n        max_tokens: maxTokens,\n        ...(outputFormat === \"json_object\" && {\n          response_format: { type: \"json_object\" },\n        }),\n      },\n      {\n        ...(kbIntegrationKey?.split(\";;\")[1] === \"credits\"\n          ? {\n              headers: {\n                \"x-buildship-workflow-id\": workflow?.id,\n                \"x-buildship-node-id\": node?.id,\n              },\n            }\n          : {}),\n      },\n    );\n    \n    const processedOutput = processResponse(response, outputFormat);\n    \n    if (sessionKey) {\n      const folderPath = path.dirname(filePath);\n      if (!fs.existsSync(folderPath)) {\n        fs.mkdirSync(folderPath, { recursive: true });\n      }\n      const dataToSave = { userRequest, assistantResponse: processedOutput };\n      fs.appendFileSync(filePath, JSON.stringify(dataToSave) + \"\\n\");\n    }\n    \n    return processedOutput;\n  } catch (e) {\n    console.error(\"Perplexity API Error:\", e);\n    throw new Error(`Perplexity API Error: ${e.message}`);\n  }\n}\n\n/**\n * Process the response from Perplexity AI API\n * @param {Object} response - The response from Perplexity AI\n * @param {String} outputFormat - The desired output format\n * @returns {Object} - Processed response with citations, content, and reasoning\n */\nfunction processResponse(response, outputFormat) {\n  // Extract content from the message\n  const messageContent = response.choices[0].message.content || \"\";\n  \n  // Extract citations if they exist in the response\n  const citations = response.citations || [];\n  \n  // Extract reasoning if it exists within <think>...</think> tags\n  let reasoning = \"\";\n  const thinkMatch = messageContent.match(/<think>([\\s\\S]*?)<\\/think>/);\n  if (thinkMatch && thinkMatch[1]) {\n    reasoning = thinkMatch[1].trim();\n  }\n  \n  // Extract the actual content (everything after the </think> tag or the whole content if no think tag)\n  let content = messageContent;\n  if (thinkMatch) {\n    content = messageContent.replace(/<think>[\\s\\S]*?<\\/think>\\s*/, \"\").trim();\n  }\n  \n  // Handle citation references in content (e.g., [1], [2], etc.)\n  // Remove citation references from the content\n  content = content.replace(/\\[\\d+\\]/g, \"\").trim();\n  \n  // Parse JSON content if needed\n  let parsedContent = content;\n  if (outputFormat === \"json_object\") {\n    try {\n      parsedContent = JSON.parse(content || \"{}\");\n    } catch (e) {\n      console.warn(\"Failed to parse JSON response:\", e.message);\n      parsedContent = { error: \"Invalid JSON response\", raw: content };\n    }\n  }\n  \n  // Prepare the final output based on the desired format\n  const result = {\n    citations: citations.reduce((acc, url, index) => {\n      acc[index + 1] = url;\n      return acc;\n    }, {}),\n    content: outputFormat === \"json_object\" ? parsedContent : content,\n    reasoning: reasoning || undefined\n  };\n  \n  // If reasoning is empty, don't include it in the output\n  if (!reasoning) {\n    delete result.reasoning;\n  }\n  \n  return result;\n}","buildshipKey":true,"type":"script","inputs":{"structure":[{"index":0,"parentId":null,"id":"systemPrompt","depth":0},{"depth":0,"index":1,"parentId":null,"id":"userRequest"},{"parentId":null,"id":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","children":[{"index":0,"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","id":"model","depth":1},{"index":1,"depth":1,"id":"sessionKey","parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82"},{"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","depth":1,"index":2,"id":"conversationLimit"},{"id":"temperature","parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","index":3,"depth":1},{"index":4,"depth":1,"id":"maxTokens","parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82"},{"parentId":"section_a1671ee7_0f0a_4eac_9307_4337093fff82","index":5,"depth":1,"id":"output_format"}],"index":2,"depth":0}],"sections":{"section_a1671ee7_0f0a_4eac_9307_4337093fff82":{"buildship":{"collapseByDefault":true,"index":2},"title":"Advanced Settings","type":"section"}},"type":"object","properties":{"systemPrompt":{"properties":{},"title":"Instructions","default":"","description":"The system's prompt message.","buildship":{"defaultExpressionType":"text","placeholder":"System default","sensitive":false,"index":0},"type":"string"},"conversationLimit":{"description":"The number of the last messages to be fetched from the storage file. Keep this low, as Perplexity has low input tokens.","properties":{},"type":"number","default":2,"title":"Conversation Limit","buildship":{"index":2.4,"sensitive":false,"defaultExpressionType":"text"}},"userRequest":{"description":"The user's message to the chat.","default":"Generate 5 tools for AI agents to call via an API that handle specific business tasks, with a one-sentence summary of inputs, logic flows (leveraging LLMs, image, or data / knowledge base analysis), external connections needed, and expected outputs.","title":"Prompt","properties":{},"type":"string","buildship":{"defaultExpressionType":"text","index":1,"sensitive":false}},"model":{"type":"string","properties":{},"buildship":{"defaultExpressionType":"text","sensitive":false,"options":[{"value":"sonar-deep-research","label":"sonar-deep-research"},{"label":"sonar-reasoning-pro","value":"sonar-reasoning-pro"},{"label":"sonar-reasoning","value":"sonar-reasoning"},{"value":"sonar-pro","label":"sonar-pro"},{"label":"sonar","value":"sonar"},{"value":"llama-3.1-sonar-small-128k-online","label":"llama-3.1-sonar-small-128k-online"},{"label":"r1-1776","value":"r1-1776"}],"index":2.2},"enum":["sonar-deep-research","sonar-reasoning-pro","sonar-reasoning","sonar-pro","sonar","llama-3.1-sonar-small-128k-online","r-1-1776"],"default":"sonar-pro","description":"Select a Perplexity AI model.","pattern":"","title":"Model"},"maxTokens":{"properties":{},"title":"Max Tokens","buildship":{"defaultExpressionType":"text","sensitive":false,"index":2.6},"type":"number","description":"The maximum number of tokens to generate in the response","default":1600},"output_format":{"description":"The format of the output","buildship":{"sensitive":false,"index":2.7,"defaultExpressionType":"text","options":[{"label":"Text","value":"text"},{"value":"json_object","label":"JSON Object"}]},"type":"string","default":"text","properties":{},"enum":["text","json_object"],"title":"Output Format"},"temperature":{"description":"The temperature for the output","default":0.5,"type":"number","title":"Temperature","buildship":{"index":2.5,"defaultExpressionType":"text","sensitive":false},"properties":{}},"sessionKey":{"buildship":{"defaultExpressionType":"text","index":2.3,"placeholder":"session-xyz-123","sensitive":false},"properties":{},"default":"","title":"Session Key","type":"string","description":"Unique key to identify the conversation session for history retrieval."}},"required":["outputFormat","userRequest","model"]},"_libRef":{"integrity":"v3:a72fd1719ea3befc10f0bf3b99f8ec9e","version":"5.0.7","libType":"public","src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/keyless-perplexity-chat/5.0.7/build.cjs","libNodeRefId":"@buildship/keyless-perplexity-chat","buildHash":"4d5fc90ac1e91cd6276b572495ccde63ac5e63efb3eda8d42715590917241e2c","isDirty":false},"dependencies":{"path":"0.12.7","fs":"0.0.2","openai":"4.87.4"},"_groupInfo":{"category":"AI Models","acceptsKey":true,"uid":"perplexity","description":"Nodes to leverage Perplexity AI's blazingly fast LLM inference.","iconUrl":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fperplexity.png?alt=media&token=c2b4b546-a17f-4866-8635-73377b79bca4","id":"perplexity","keyDescription":"Perplexity AI API Key. Generate an API key through the [Perplexity Account Settings Page](https://www.perplexity.ai/settings).","name":"Perplexity AI","longDescription":"Integrate Perplexity AI's advanced language model with BuildShip to enhance your AI-driven workflows. Utilize predefined nodes to perform rapid and efficient natural language processing tasks, enabling capabilities such as text generation, summarization, and contextual analysis effortlessly within your applications."},"output":{"title":"Response","buildship":{},"type":"string","description":"The response text or JSON object."}},{"inputs":{"structure":[{"parentId":null,"id":"systemPrompt","index":0,"depth":0},{"depth":0,"parentId":null,"id":"userPrompt","index":1},{"parentId":null,"id":"response_schema","depth":0,"index":2},{"depth":0,"index":3,"parentId":null,"children":[{"id":"maxTokens","index":0,"parentId":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982","depth":1},{"index":1,"id":"temperature","depth":1,"parentId":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982"},{"depth":1,"parentId":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982","id":"model","index":2}],"id":"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982"}],"required":["apiKey","systemPrompt","userPrompt","response_schema","model"],"properties":{"response_schema":{"buildship":{"defaultExpressionType":"schema","sensitive":false,"index":2},"description":"The response schema can be created using the Schema Builder.\n\nIt can also be created as a plain object in the JavaScript editor and it should be in a standard JSON Schema format.\n\n```\n{\n  \"type\": \"json_schema\",\n  \"json_schema\": {\n    \"name\": \"response\",\n    \"strict\": true,\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {},\n      \"required\": [],\n      \"additionalProperties\": false,\n      \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    },\n  },\n}\n```\n","pattern":"","properties":{},"type":"object","title":"Schema","default":{"_$expression_":"","_$schema_":[{"required":true,"type":"string","name":"weather"},{"name":"temperature","required":true,"type":"number"},{"type":"string","name":"description","required":true},{"type":"boolean","name":"isRaining","required":true}],"type":"schema"}},"maxTokens":{"title":"Max Tokens","default":800,"pattern":"","description":"The maximum length (in tokens) of the generated JSON.","buildship":{"sensitive":false,"index":3.2},"type":"number"},"systemPrompt":{"default":"Convert the input text into JSON following the schema exactly.","pattern":"","title":"Instructions","type":"string","buildship":{"sensitive":false,"index":0,"placeholder":""},"description":"The system prompt to generate JSON from.\n\n**When using this node, always instruct the model to produce JSON using the provided Schema.**\n\n**SAMPLE PROMPT**:\n```\nYou are a helpful math tutor. Only use the schema for math responses.\n```","properties":{}},"userPrompt":{"buildship":{"placeholder":"Your Unstructured Text","sensitive":false,"index":1},"pattern":"","type":"string","description":"The user prompt to generate JSON from.","default":"The weather today is sunny with a temperature of 75 degrees.","properties":{},"title":"Input"},"temperature":{"pattern":"","buildship":{"sensitive":false,"index":3.3},"type":"number","description":"As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions.\n\n**RANGE: `0 to 1`**","default":0.1,"title":"Temperature","properties":{}},"model":{"enum":["gpt-4.1","gpt-4o-mini","gpt-4o"],"buildship":{"defaultExpressionType":"text","sensitive":false,"index":3.4,"options":[{"value":"gpt-4.1","label":"gpt-4.1"},{"value":"gpt-4o-mini","label":"gpt-4o-mini"},{"value":"gpt-4o","label":"gpt-4o"}]},"title":"Model","type":"string","properties":{},"description":"The OpenAI Model to use for performing the JSON Generation.","default":"gpt-4o-2024-08-06","pattern":""}},"sections":{"section_7e3a2fb9_274c_4da7_a080_cedb4dec9982":{"title":"Advanced","type":"section","buildship":{"index":3,"collapsed":true}}},"type":"object"},"dependencies":{"openai":"4.95.0"},"meta":{"description":"A keyless node that generates perfectly structured JSON using OpenAI's Structured Outputs, ensuring strict adherence to a provided schema.","name":"JSON Generator","icon":{"type":"URL","url":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fopenai.png?alt=media&token=9c513dd1-e2d4-47d2-8e3c-3a1a6ebf03e3&_gl=1*b90bgk*_ga*MjAxOTYxMjk5OS4xNjk0NTIzMjQ2*_ga_CW55HF8NVT*MTY5NjQwMzEyMy4yNS4xLjE2OTY0MDMxNDQuMzkuMC4w"},"id":"openai-json-schema-generator"},"id":"ba37ffeb-278c-4289-a467-b3d155c940b8","buildshipKey":true,"type":"script","_libRef":{"isDirty":false,"integrity":"v3:b0f8e77b632793a3ae59c684f8258821","version":"2.1.11","src":"https://storage.googleapis.com/buildship-app-us-central1/publicLib/nodesV2/@buildship/openai-json-schema-generator/2.1.11/build.cjs","buildHash":"2d4824f0e396200f8e154ff90d9af6879d4a8bd750b16fda5f95861c7a72ddca","libType":"public","libNodeRefId":"@buildship/openai-json-schema-generator"},"script":"import OpenAI from \"openai\";\n\nconst getAccessToken = async () => {\n  const response = await fetch(\n    \"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n    { headers: { \"Metadata-Flavor\": \"Google\" } }\n  );\n  if (!response.ok) {\n    throw new Error(`Failed to obtain access token: ${response.statusText}`);\n  }\n  const data: any = await response.json();\n  return data?.access_token;\n};\n\nexport default async function openaiGptTextGenerator(\n  {\n    userPrompt,\n    systemPrompt,\n    maxTokens,\n    temperature,\n    model,\n    response_schema,\n    kbIntegrationKey,\n  }: NodeInputs & { kbIntegrationKey: string },\n  { auth, workflow, node }: NodeScriptOptions\n): NodeOutput {\n  const hasCredits = kbIntegrationKey?.split(\";;\")[1] === \"credits\";\n  const apiKey = hasCredits ? await getAccessToken() : auth.getKey();\n\n  if (!apiKey) {\n    throw new Error(\n      \"An integration key is required for this node to function, but no key was selected. Please select one from the node's toolbar.\"\n    );\n  }\n\n  const client = new OpenAI({\n    apiKey,\n    ...(hasCredits && { baseURL: \"https://proxy.buildship.run/llm/openai\" }),\n  });\n\n\n  const response = await client.responses.create(\n    {\n      model,\n      input: [\n        {\n          role: \"system\",\n          content: systemPrompt,\n        },\n        {\n          role: \"user\",\n          content: userPrompt,\n        },\n      ],\n      text: {\n        format: transformResponseSchema(response_schema),\n      },\n      max_output_tokens: maxTokens,\n      temperature,\n    },\n    hasCredits\n      ? {\n          headers: {\n            \"x-buildship-workflow-id\": workflow?.id,\n            \"x-buildship-node-id\": node?.id,\n          },\n        }\n      : undefined\n  );\n\n  try {\n    return JSON.parse(response.output_text);\n  } catch (e) {\n    throw new Error(\"Failed to parse response output_text as JSON.\");\n  }\n}\n\n\nfunction transformResponseSchema(response_schema: any) {\n  if (!response_schema?.json_schema?.schema) {\n    throw new Error(\"Invalid or missing response_schema format.\");\n  }\n\n  const UNSUPPORTED_BY_TYPE: Record<string, string[]> = {\n    string: [\"minLength\", \"maxLength\", \"pattern\", \"format\"],\n    number: [\"minimum\", \"maximum\", \"multipleOf\"],\n    object: [\n      \"patternProperties\", \"unevaluatedProperties\", \"propertyNames\",\n      \"minProperties\", \"maxProperties\"\n    ],\n    array: [\n      \"unevaluatedItems\", \"contains\", \"minContains\", \"maxContains\",\n      \"minItems\", \"maxItems\", \"uniqueItems\"\n    ],\n  };\n\n  const clean = (schema: any, inProps = false): any => {\n    if (Array.isArray(schema)) return schema.map((s) => clean(s, inProps));\n    if (typeof schema !== \"object\" || schema === null) return schema;\n\n    const type = schema.type;\n    const unsupported = inProps ? [] : (UNSUPPORTED_BY_TYPE[type] || []);\n    \n    return Object.fromEntries(\n      Object.entries(schema).map(([k, v]) => {\n        if (unsupported.includes(k)) return null;\n        const nested = k === \"properties\" ? clean(v, true) : clean(v, false);\n        return [k, nested];\n      }).filter(Boolean)\n    );\n  };\n\n  return {\n    type: \"json_schema\",\n    name: response_schema.json_schema.name || \"response\",\n    strict: true,\n    schema: clean(response_schema.json_schema.schema),\n  };\n}\n","_groupInfo":{"keyDescription":"Add your OpenAI API Key. Get it from your [OpenAI account](https://platform.openai.com/account/api-keys)","id":"ZBwcODUEhzNMxYxpN1O8","icon":null,"acceptsKey":true,"iconUrl":"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2Fopenai.png?alt=media&token=9c513dd1-e2d4-47d2-8e3c-3a1a6ebf03e3","category":"AI Models","description":"OpenAI Models","uid":"openai","details":null,"longDescription":"BuildShip allows you to effortlessly integrate OpenAI models into your workflows, enabling the use of advanced machine learning capabilities for text generation, translation, and more. Streamline processes by utilizing AI-powered models to enhance automation, decision-making, and content generation in a seamless and efficient manner.","name":"OpenAI"},"integrations":[],"output":{"description":"The text generated by the OpenAI GPT API","title":"Generated Text","type":"object","properties":{},"buildship":{}},"label":"Startup Scoring"},{"type":"output","id":"c7bb3920-50be-4031-a5f6-e333f7054b21","label":"Flow Output"}],"triggers":[{"response":{"title":"Response","structure":[{"index":1,"depth":0,"id":"body","parentId":null},{"depth":0,"id":"status","parentId":null,"index":0},{"parentId":null,"index":2,"id":"cacheMaxAge","depth":0}],"type":"object","required":["body"],"properties":{"cacheMaxAge":{"properties":{},"buildship":{"sensitive":false,"index":2},"description":"Set cache duration in seconds","type":"number","title":"Cache Time","default":0},"body":{"type":"object","description":"Body of the response","properties":{},"title":"Response Body","buildship":{"sensitive":false,"index":1},"default":{"_$keys_":["output"]}},"status":{"description":"The HTTP status code to return","enum":["200","201","202","204","400","401","403","404","429","500"],"buildship":{"index":0,"options":[{"label":"OK (200)","value":"200"},{"label":"Created (201)","value":"201"},{"value":"202","label":"Accepted (202)"},{"value":"301","label":"Redirect (301)"},{"label":"No Content (204)","value":"204"},{"value":"400","label":"Bad Request (400)"},{"label":"Unauthorized (401)","value":"401"},{"label":"Forbidden (403)","value":"403"},{"label":"Not Found (404)","value":"404"},{"label":"Too Many Requests (429)","value":"429"},{"label":"Internal Server Error (500)","value":"500"}]},"default":"200","title":"Status code","type":"string"}},"sections":{}},"script":"import parser from \"co-body\";\n\nconst onExecution = async (\n\t{ method, requestContentType },\n\t{ nodeReq, request, logging }\n) => {\n\tlet body;\n\tif (method !== \"GET\") {\n        const limit = process.env?.PROJECT_PLAN === \"FREE\" ? \"1MB\" : \"32MB\";\n\t\t//const parser = require('co-body');\n\t\t//const parser = await import('co-body');\n\t\tswitch (requestContentType) {\n\t\t\tcase \"text/plain\":\n\t\t\t\tbody = await parser.text(nodeReq, { limit });\n\t\t\t\tbreak;\n\t\t\tcase \"application/x-www-form-urlencoded\":\n\t\t\t\tbody = await parser.form(nodeReq, { limit });\n\t\t\t\tbreak;\n\t\t\tcase \"application/json\":\n\t\t\t\tbody = await parser.json(nodeReq, { limit });\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tconst ret = {\n\t\tquery: request.query,\n\t\theaders: request.headers,\n\t\tbody: body !== null && body !== void 0 ? body : {},\n        params: request.params,\n        path: request.path\n\t};\n\treturn ret;\n};\n\nconst getAccessToken = async () => {\n\tconst response = await fetch(\n\t\t\"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n\t\t{\n\t\t\theaders: { \"Metadata-Flavor\": \"Google\" },\n\t\t}\n\t);\n\n\tif (!response.ok) {\n\t\tthrow new Error(\n\t\t\t`Failed to obtain access token: ${response.statusText}`\n\t\t);\n\t}\n\n\tconst data = await response.json();\n\treturn data.access_token;\n};\n\nconst fetchLogEntries = async (triggerId, retries = 3, delay = 1000) => {\n\tconst projectId = process.env.GCLOUD_PROJECT;\n\tconst accessToken = await getAccessToken();\n\n\tconst filter = `logName=\"projects/${projectId}/logs/buildship-node-io\" AND jsonPayload.nId=\"${triggerId}\"`;\n\n\tconst requestBody = {\n\t\tresourceNames: [`projects/${projectId}`], // Added resourceNames field\n\t\tfilter: filter,\n\t\tpageSize: 1,\n\t\torderBy: \"timestamp desc\",\n\t};\n\n\tfor (let attempt = 1; attempt <= retries; attempt++) {\n\t\ttry {\n\t\t\tconst response = await fetch(\n\t\t\t\t\"https://logging.googleapis.com/v2/entries:list\",\n\t\t\t\t{\n\t\t\t\t\tmethod: \"POST\",\n\t\t\t\t\theaders: {\n\t\t\t\t\t\tAuthorization: `Bearer ${accessToken}`,\n\t\t\t\t\t\t\"Content-Type\": \"application/json\",\n\t\t\t\t\t},\n\t\t\t\t\tbody: JSON.stringify(requestBody),\n\t\t\t\t}\n\t\t\t);\n\n\t\t\tif (!response.ok) {\n\t\t\t\tconst errorText = await response.text();\n\t\t\t\tthrow new Error(\n\t\t\t\t\t`Error fetching log entries: ${response.statusText} - ${errorText}`\n\t\t\t\t);\n\t\t\t}\n\n\t\t\tconst data = await response.json();\n\t\t\tconst entries = data.entries || [];\n\n\t\t\tif (entries.length > 0) {\n\t\t\t\treturn entries;\n\t\t\t}\n\n\t\t\t// Delay before the next attempt if entries were empty\n\t\t\tif (attempt < retries) {\n\t\t\t\tawait new Promise((resolve) => setTimeout(resolve, delay));\n\t\t\t}\n\t\t} catch (error) {\n\t\t\tconsole.error(`Attempt ${attempt} failed due to an error:`, error);\n\t\t\t// Retry if it's not the last attempt\n\t\t\tif (attempt < retries) {\n\t\t\t\tawait new Promise((resolve) => setTimeout(resolve, delay));\n\t\t\t} else {\n\t\t\t\tthrow new Error(\n\t\t\t\t\t`Failed to get data after ${retries} attempts.`\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t}\n\n\t// If all retries exhausted and no entries found\n\tthrow new Error(\"No data found. Send a request to the API and try again.\");\n};\n\nconst getData = async (inputs, { trigger, workflow }) => {\n\ttry {\n\t\tconst entries = await fetchLogEntries(trigger.id, 5, 2000);\n\t\treturn { success: true, message: \"\", data: entries[0].jsonPayload.o };\n\t} catch (err) {\n\t\treturn { success: false, message: err?.message, data: null };\n\t}\n};\n\nexport default { onExecution, onCreate: () => {}, onUpdate: () => {}, getData };\n\n","config":{"type":"object","sections":{"section_e5935beb_b40e_437c_b484_66fa67eccbfa":{"title":"Advanced Options","buildship":{"index":2},"type":"section"}},"structure":[{"index":0,"id":"path","depth":0,"parentId":null},{"parentId":null,"depth":0,"index":1,"id":"method"},{"parentId":null,"depth":0,"id":"section_e5935beb_b40e_437c_b484_66fa67eccbfa","index":2,"children":[{"id":"requestContentType","parentId":"section_e5935beb_b40e_437c_b484_66fa67eccbfa","index":0,"depth":1}]}],"properties":{"requestContentType":{"properties":{},"title":"Request Content Type","enum":["application/json","application/x-www-form-urlencoded","text/plain"],"buildship":{"index":2.2,"options":[{"value":"application/json","label":"JSON (application/json)"},{"value":"application/x-www-form-urlencoded","label":"Form (application/x-www-form-urlencoded)"},{"value":"text/plain","label":"Text (text/plain)"}],"sensitive":false},"default":"application/json","type":"string"},"path":{"type":"string","pattern":"^\\/[^\\s?#]*$","properties":{},"title":"Path","buildship":{"sensitive":false,"index":0},"default":"/","description":"Path of the endpoint"},"method":{"title":"Method","default":"POST","description":"HTTP method","enum":["POST","GET","PUT","DELETE"],"type":"string","buildship":{"options":[{"value":"POST","label":"POST"},{"value":"GET","label":"GET"},{"value":"PUT","label":"PUT"},{"label":"DELETE","value":"DELETE"}],"index":1}}},"required":["method","path"]},"id":"66fec945-2192-4dd9-bb4a-cd22e8eb2181","usage":"<>\n  <ClipboardTextArea\n    label=\"Endpoint URL\"\n    content={`${props.host}${props.triggerValues?.[\"config.path\"]}`}\n  />\n\n  <Typography sx={{ marginTop: \"16px\" }}>Code Snippet</Typography>\n\n  <Typography\n    sx={(theme) => ({ color: theme.palette.text[400], marginTop: \"4px\" })}\n  >\n    {\"Copy and paste the code snippet to your app or website.\"}\n  </Typography>\n  <div style={{ marginTop: \"16px\" }}>\n    <CodeSamples\n      samples={[\n        {\n          code: `async function callEndpoint(${Object.keys(props.inputs.properties ?? {}).join(\", \")}) {\n    const url = '${props.host}${props.triggerValues?.[\"config.path\"]}';\n    ${\n      props.triggerValues?.[\"config.method\"] === \"GET\"\n        ? \"\"\n        : `const data = {\n        ${Object.keys(props.inputs.properties ?? {})\n          .map((key) => key + \": \" + key)\n          .join(\",\\n\")}\n    }`\n    }\n    try {\n        const response = await fetch(url, {\n            method: '${props.triggerValues?.[\"config.method\"]}',\n            headers: {${\n              props.triggerValues?.[\"config.method\"] === \"GET\"\n                ? \"\"\n                : `\n               'Content-Type': '${props.triggerValues?.[\"config.requestContentType\"]}',`\n            }\n            },\n            ${props.triggerValues?.[\"config.method\"] === \"GET\" ? \"\" : \"body: JSON.stringify(data)\"}\n        });\n        const result = await response.json();\n        console.log('Success:', result);\n        return result;\n    } catch (error) {\n        console.error('Error:', error);\n    }\n}`,\n          language: \"js\",\n          label: \"JavaScript\",\n        },\n      ]}\n    />\n  </div>\n\n  {(() => {\nconst prompt = `Create an intuitive & responsive webapp using the given endpoint and the example inputs\n\nRules:\n- Use only the inputs given. \n- Include validation for required fields if needed.\n- Handle the output properly depending what it returns (string, number, etc) specially in case of returning lists or json outputs.\n\nasync function callEndpoint(${Object.keys(props.inputs.properties ?? {}).join(\", \")}) {\n    const url = '${props.host}${props.triggerValues?.[\"config.path\"]}';\n    ${props.triggerValues?.[\"config.method\"] === \"GET\" \n        ? \"\" \n        : `const data = {\n            ${Object.keys(props.inputs.properties ?? {})\n                .map((key) => `${key}: ${key}`)\n                .join(\",\\n            \")}\n        }`\n    }\n    \n    try {\n        const response = await fetch(url, {\n            method: '${props.triggerValues?.[\"config.method\"]}',\n            headers: {${props.triggerValues?.[\"config.method\"] === \"GET\"\n                ? \"\"\n                : `\n                'Content-Type': '${props.triggerValues?.[\"config.requestContentType\"]}',`\n            }},\n            ${props.triggerValues?.[\"config.method\"] === \"GET\" ? \"\" : \"body: JSON.stringify(data)\"}\n        });\n        \n        const result = await response.json();\n        console.log('Success:', result);\n        return result;\n    } catch (error) {\n        console.error('Error:', error);\n    }\n}\n\nHere are sample inputs: \n${props.getInputTypes ? props.getInputTypes(props.inputs || {}) : `{\n  ${Object.entries(props.inputs?.properties ?? {}).map(([key,value]) => `${key}: ${value.type}`).join(\",\\n    \")}\n}`}\n\n\nThe output of this endpoint is:\n${props.getInputTypes ? props.getInputTypes(props.output || {}) : `{\n  ${Object.entries(props.output?.properties ?? {}).map(([key,value]) => `${key}: ${value.type}`).join(\",\\n    \")}\n}`}\n\n\n\n`;\n  \n    return (\n      <>\n        <Typography sx={{ marginTop: \"16px\" }}>AI Handoff</Typography>\n        <Typography\n          sx={(theme) => ({ color: theme.palette.text[400], marginTop: \"4px\" })}\n        >\n          Paste the following prompt into your AI App builder to generate the\n          frontend by connecting to your BuildShip API endpoint and creating the\n          UI you need.\n        </Typography>\n\n        <div\n          style={{\n            width: \"100%\",\n            display: \"flex\",\n            alignItems: \"center\",\n            justifyContent: \"space-between\",\n            margin: \"16px 0 \",\n          }}\n        >\n          <Typography>Prompt</Typography>\n          <CopyButton variant=\"expanded\" label=\"Copy prompt\" content={prompt} />\n        </div>\n\n        <CodeViewer copy={false} code={prompt} />\n\n        <div style={{ height: \"120px\" }} />\n      </>\n    );\n  })()}\n</>\n","label":"REST API Call","defaultValues":{"path":"'/' + props.wfName + '-' + props.triggerId.split('-').slice(-1).join('')","inputs":"{ _$expression_: 'ctx?.[\"root\"]?.[\"' + props.triggerId + '\"]?.[\"' + (props.method === 'GET' ? 'query' : 'body') + '\"].' + props.inputKey }"},"dependencies":{"require":"2.4.20","import":"0.0.6","co-body":"6.2.0"},"_libRef":{"integrity":"v3:5cc848f9143c4eb3ec08e5c2db72548c","libNodeRefId":"@buildship/http-v2","isDirty":false,"libType":"public","src":"https://storage.googleapis.com/buildship-library-us-central1/triggers/@buildship/http-v2/1.0.35/__verify.cjs","version":"1.0.35"},"type":"http-v2","usagePreview":"<div\n  style={{\n    margin: \"22px\",\n    padding: \"24px\",\n    backgroundColor: props.theme.palette.elevation.sections,\n    boxShadow: \"0px 4px 16px 0px rgba(0, 0, 0, 0.08)\",\n    borderRadius: \"16px\",\n  }}\n>\n  <Typography\n    sx={(theme) => ({ ...theme.typography.headline5, marginBottom: \"24px\" })}\n  >\n    {\"Rest API Call\"}\n  </Typography>\n  <TestPanel selectedSegmentToTestId=\"workflow\" />\n</div>\n","data":{"required":["body"],"title":"Request","type":"object","description":"Named URL parameters","buildship":{},"properties":{"body":{"properties":{},"type":"object","default":{},"title":"Body","buildship":{"index":0,"sensitive":true}},"params":{"properties":{},"type":"object","buildship":{"index":3},"title":"Params","description":"Named URL parameters"},"headers":{"properties":{"origin":{"type":"string","properties":{},"title":"origin","buildship":{"index":0,"sensitive":true},"default":""},"x-cloud-trace-context":{"type":"string","properties":{},"default":"","buildship":{"sensitive":true,"index":1},"title":"x-cloud-trace-context"},"authorization":{"title":"authorization","buildship":{"index":2},"type":"string"}},"type":"object","title":"Headers","description":"Headers of the request","buildship":{"index":0,"sensitive":true},"default":{}},"query":{"type":"object","buildship":{"index":2},"title":"Query","description":"Query parameters of the request"},"requestPath":{"buildship":{"index":4},"title":"Request Path","description":"","type":"string"}}},"lastDeploymentHash":"UdJICyEGPvjH/LTKDX1CdzC62EP2xNAPkEdqDbzHpVQ=","lifeCycleFunctions":["onExecution","onCreate","onUpdate","getData"],"preSetupPreview":"<div\n  style={{\n    margin: \"22px\",\n    padding: \"24px 42px\",\n    marginTop: \"240px\",\n    display: \"flex\",\n    alignItems: \"center\",\n    justifyContent: \"center\",\n    flexDirection: \"column\",\n  }}\n>\n  <div\n    style={{\n      display: \"flex\",\n      padding: \"8px\",\n      backgroundColor: props.theme.palette.text[50],\n      borderRadius: \"8px\",\n    }}\n  >\n    <SvgIcon>\n      <svg width=\"16\" height=\"16\" viewBox=\"0 0 16 16\" fill=\"currentColor\" xmlns=\"http://www.w3.org/2000/svg\">\n        <path d=\"M8.47141 3.41397C8.21106 3.15362 7.78895 3.15362 7.52861 3.41397L6.60949 4.33309C6.34914 4.59344 5.92703 4.59344 5.66668 4.33309C5.40633 4.07274 5.40633 3.65063 5.66668 3.39028L6.5858 2.47116C7.36685 1.69011 8.63317 1.69011 9.41422 2.47116L10.3333 3.39028C10.5937 3.65063 10.5937 4.07274 10.3333 4.33309C10.073 4.59344 9.65088 4.59344 9.39053 4.33309L8.47141 3.41397ZM7.5285 12.5853C7.78885 12.8456 8.21096 12.8456 8.47131 12.5853L9.39043 11.6662C9.65078 11.4058 10.0729 11.4058 10.3332 11.6662C10.5936 11.9265 10.5936 12.3486 10.3332 12.609L9.41412 13.5281C8.63307 14.3092 7.36674 14.3092 6.5857 13.5281L5.66658 12.609C5.40623 12.3486 5.40623 11.9265 5.66658 11.6662C5.92693 11.4058 6.34903 11.4058 6.60938 11.6662L7.5285 12.5853ZM12.5859 7.69527C12.8463 7.95562 12.8463 8.37773 12.5859 8.63808L11.6668 9.5572C11.4065 9.81755 11.4065 10.2397 11.6668 10.5C11.9272 10.7604 12.3493 10.7604 12.6096 10.5L13.5288 9.58089C14.3098 8.79984 14.3098 7.53351 13.5288 6.75246L12.6096 5.83334C12.3493 5.57299 11.9272 5.57299 11.6668 5.83334C11.4065 6.09369 11.4065 6.5158 11.6668 6.77615L12.5859 7.69527ZM3.41397 7.69502C3.15362 7.95537 3.15362 8.37748 3.41397 8.63783L4.33309 9.55695C4.59344 9.8173 4.59344 10.2394 4.33309 10.4998C4.07274 10.7601 3.65063 10.7601 3.39028 10.4998L2.47116 9.58064C1.69011 8.79959 1.69011 7.53326 2.47116 6.75221L3.39028 5.83309C3.65063 5.57274 4.07274 5.57274 4.33309 5.83309C4.59344 6.09344 4.59344 6.51555 4.33309 6.7759L3.41397 7.69502ZM7.99996 9.33329C8.73634 9.33329 9.33329 8.73634 9.33329 7.99996C9.33329 7.26358 8.73634 6.66663 7.99996 6.66663C7.26358 6.66663 6.66663 7.26358 6.66663 7.99996C6.66663 8.73634 7.26358 9.33329 7.99996 9.33329Z\"/>\n      </svg>\n    </SvgIcon>\n  </div>\n  <br />\n  <Typography\n    sx={(theme) => ({\n      ...theme.typography.body,\n      color: props.theme.palette.text[400],\n      textAlign: \"center\",\n    })}\n  >\n    Finish your setup for creating your first endpoint\n  </Typography>\n</div>","description":"Create an API / HTTP endpoint as the trigger or starting point for your workflow. This endpoint can be used in other apps to run the workflow. [Full Documentation](https://docs.buildship.com/trigger-nodes/rest-api).","setupPreview":"<div\n  style={{\n    display: \"flex\",\n    // height: \"700px\",\n    // overflowY: \"auto\",\n    alignItems: \"center\",\n    justifyContent: \"center\",\n    flexDirection: \"column\",\n    // margin: \"22px\",\n    padding: \"22px\",\n  }}\n>\n  <div\n    style={{\n      padding: \"24px\",\n      backgroundColor: props.theme.palette.elevation.sections,\n      boxShadow: \"0px 4px 16px 0px rgba(0, 0, 0, 0.08)\",\n      borderRadius: \"16px\",\n      width: \"100%\"\n    }}\n  >\n    <Typography sx={{ marginBottom: \"8px\" }}>{\"Your trigger is ready to receive data!\"}</Typography>\n    <Typography sx={(theme) => ({ color: theme.palette.text[400], marginBottom: \"24px\" })}>\n      Send a request and use the received data to define your workflow input schema.\n    </Typography>\n    <ClipboardTextArea\n      label=\"1. Send a request\"\n      content={`${props.host}${props.triggerValues?.[\"config.path\"]}`}\n    />\n    <Typography sx={(theme) => ({ color: theme.palette.text[400], marginBottom: \"24px\" })}>\n      Send an API request to the endpoint URL above, using your external app or service.\n    </Typography>\n    <InputsBinder\n      header=\"2. Get the latest request\"\n      description=\"\"\n      trigger={props.trigger}\n      resultHeader=\"3. Select the paths to update your input schema\"\n      resultDescription=\"No data received yet!\"\n    />\n  </div>\n</div>\n","meta":{"icon":{"type":"SVG","svg":""},"payloadLimit":true,"description":"Create an API / HTTP endpoint as the trigger or starting point for your workflow. This endpoint can be used in other apps to run the workflow. [Full Documentation](https://docs.buildship.com/trigger-nodes/rest-api).","name":"REST API Call","fileUploadLimit":false,"id":"http-v2"}}],"nodeValues":{"c7ff1f45-2560-4b9e-8c91-d8367530a60f":{"oAuthIntegrations":{},"output_format":"text","temperature":0.5,"userRequest":{"_$keys_":["inputs","website"]},"kbIntegrationKey":"perplexity;;credits","maxTokens":1600,"systemPrompt":"given website, i want find out if the company has raised any funding rounds previously","sessionKey":"","conversationLimit":2,"model":"sonar-pro"},"25c02936-87a1-42eb-8d31-039e12e7ec38":{"maxTokens":1600,"userRequest":{"_$keys_":["5195fbc2-557d-4f62-baf6-251b690fea9f","3176f735-4d90-4933-b3c9-9e8d2c2b058b","summery"]},"systemPrompt":"given product summery research if you find similar companies, and return a competitor Summary","sessionKey":"","oAuthIntegrations":{},"temperature":0.5,"model":"sonar-pro","kbIntegrationKey":"perplexity;;credits","conversationLimit":2,"output_format":"text"},"test-e921fb25-0390-467d-9352-8db3d52ed27a-form":{"sessionKey":"","temperature":0.5,"outputFormat":"text","userRequest":"https://sts42.com","oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"model":"diffbot-small-xl","kbIntegrationKey":"diffbot;;credits","systemPrompt":"given website, i want find out if the company has raised any funding rounds previously","maxTokens":1600,"conversationLimit":10},"bdcef193-9e69-4d5f-808d-beafc886fd86":{"temperature":0.1,"userPrompt":{"_$expression_":"source A:\nctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"c7ff1f45-2560-4b9e-8c91-d8367530a60f\"]\n\nsource B:\nctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"e921fb25-0390-467d-9352-8db3d52ed27a\"]","type":"text","hasErrors":false},"kbIntegrationKey":"openai;;openai-key-1","oAuthIntegrations":{},"maxTokens":800,"systemPrompt":"given two sources of data combine, return json schema, funding ammount number in dollars if no funding(return 0), and reasoning","model":"gpt-4o-2024-08-06","response_schema":{"_$expression_":" ","_$schema_":[{"required":true,"type":"number","name":"fundingAmount"},{"type":"string","name":"reasoning","required":true},{"required":true,"name":"hasFunding","type":"boolean"}],"type":"schema"}},"ab3cd994-21ff-46d8-b06a-8cdc899925ef":{"temperature":0.5,"userPrompt":{"_$expression_":"JSON.stringify({\n  sourceA: ctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"80488f56-ebe0-4148-a119-366243385f89\"]?.map(_=>_?.[\"d965b4ec-47db-4e69-a1e8-e5563f63f7c8\"]?.[\"7111a5bf-8742-4992-b31c-97bcfb390b79\"]),\n  sourceB: ctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"80488f56-ebe0-4148-a119-366243385f89\"]?.map(_=>_?.[\"d965b4ec-47db-4e69-a1e8-e5563f63f7c8\"]?.[\"8cfd7e60-42b8-43ce-aa1b-8b6ce7b99542\"])\n})","type":"javascript","hasErrors":false},"conversationLimit":10,"oAuthIntegrations":{},"systemPrompt":{"_$expression_":"given company (ctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"3176f735-4d90-4933-b3c9-9e8d2c2b058b\"].companyName) summery: \nctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"3176f735-4d90-4933-b3c9-9e8d2c2b058b\"]?.[\"summery\"]\n\nevalute if provided team bios are good product founder fit return analysis and nice markdown with emojis","hasErrors":false,"type":"text"},"maxTokens":1600,"modelId":"claude-3-7-sonnet-20250219","kbIntegrationKey":"anthropic;;credits"},"test-3176f735-4d90-4933-b3c9-9e8d2c2b058b-form":{"model":"gpt-4.1","maxTokens":1000,"oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"temperature":0.1,"response_schema":{"_$expression_":"{\"type\":\"json_schema\",\"json_schema\":{\"name\":\"response\",\"strict\":true,\"schema\":{\"type\":\"object\",\"properties\":{\"team\":{\"items\":{\"properties\":{\"name\":{\"type\":\"string\"},\"role\":{\"type\":\"string\"}},\"required\":[\"name\",\"role\"],\"additionalProperties\":false,\"type\":\"object\"},\"type\":\"array\"},\"moat\":{\"type\":\"string\"},\"market\":{\"type\":\"string\"},\"summery\":{\"type\":\"string\"},\"keyDifferentiation\":{\"type\":\"string\"},\"traction\":{\"type\":\"string\"},\"redFlags\":{\"items\":{\"type\":\"string\"},\"type\":\"array\"},\"highlights\":{\"items\":{\"type\":\"string\"},\"type\":\"array\"},\"founders\":{\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"name\":{\"type\":\"string\"},\"role\":{\"type\":\"string\"}},\"required\":[\"name\",\"role\"],\"additionalProperties\":false}},\"companyName\":{\"type\":\"string\"}},\"required\":[\"moat\",\"keyDifferentiation\",\"traction\",\"highlights\",\"market\",\"summery\",\"companyName\",\"redFlags\",\"team\",\"founders\"],\"additionalProperties\":false,\"$schema\":\"http://json-schema.org/draft-07/schema#\"}}}","type":"javascript"},"kbIntegrationKey":"openai;;credits","systemPrompt":"Convert the input text of pitch deck into JSON following the schema exactly. If you cant find something in the provided deck you can set it as \"NA\"","userPrompt":"Website Content:\nPricingHave an account? Login!HelpFrançaisEspañolStrategic Thinking SystemsCollaborate, align, decide and plan  with the help of agentic and copilot AI.Streamline your workflows, enhance productivity, and boost team autonomy with STS, the AI-driven project planning and alignment platform designed to elevate your projects and keep you in control.Get Started FreeIncrease efficiency. Reduce friction. Get your strategy and projects right.Why choose STS for project planning?At STS, we enhance decision-making through a powerful combination of AI-powered agentic and copilot tools.Our platform serves as your virtual project consultant, helping you and your team clarify ideas, plan efficiently, and execute with precision.STS adapts to your workflow, letting you chain agents, customize tasks, and build reusable templates—all while keeping you fully in control. Increase Productivity: Customize tasks and streamline workflows to enable project managers to manage higher workloads more effectively. Faster Onboarding: Let newer and less experienced project managers access insights and guidance on terminology, methodology and best practices . Higher Success Rate: Achieve stakeholder alignment, enhance risk management, and reduce the likelihood of pursuing the wrong outcome.“Finally, a tool for project initiation! With STS, what normally takes 1–2 weeks was done in just one hour!” - Project Management Certified TrainerGet Started FreeImprove resource allocation efficiency by conducting a thorough needs assessment and reallocating resources accordinglyKey features that make STS stand outAgent Chaining for Customizable WorkflowsLink tasks and automate repetitive steps while tailoring each project’s flow.Probing and Nudging Copilot to Start and Stay on the Right TrackOur Question Assistant copilot asks targeted questions to guide your detailed inputs, ensuring precise AI responses that deliver top-quality insights at every stage.Reusable TemplatesSave time by creating templates for recurring tasks, so you can focus on what matters most.AI Advisor AccessGet actionable advice on complex decisions, from compliance to risk management to strategic planning.“I asked Microsoft Copilot for assistance converting energy figures from various sources. I spotted some mistakes in its answers, then wrestled 30 minutes trying to make it correct them. I went through the same exercise with STS and got all I needed in 5 minutes.” - Sustainability expertTRY STS FreeIncrease approval rates for projects by enhancing compliance documentation and stakeholder engagement processes.Testimonials“People feel overwhelmed by ChatGPT. When I saw how STS solves this, it was obvious to me how much more powerful it was. I fell in love immediately!” - Business consultant“We ran a brainstorming session with six professionals from three countries, each with their unique skills and preferences regarding how to tackle an issue. We were amazed by all that we accomplished in one session, and how STS seamlessly allowed everyone to contribute in its own way.” - Head of marketing and innovation\"“The STS platform allows me to develop and manage various project components within a single view, while keeping them logically separated. This enables independent analysis, sorting, and modification, while still maintaining the entire project for quick reference as well as the ability to run additional AI agents on specific sections as needed. The platform lets me refine the plan one section (or step) at a time, keeping everything well-organized and easily accessible.” - Technical Program ManagerSee How STS Works for YouIncrease ROI by refining targeting strategies and optimizing ad spend.How it works: Simple steps to get started1 Sign UpCreate your account in seconds. It's free for ever!2 Set Up ProjectsStart with a template. Tailor it to your needs.3 Engage with AI AdvisorsGet actionable suggestions. Move projects forward, with confidence.Sign Up Now – It's Free!The STS storySTS was built with the anticipation that as AI becomes more competent, we would need better interfaces to collaborate with it. We are here now.Built by Entrepreneurs for Innovators With involvement in 25 startups and successful exits, CEO, Francis Dion recognized the limitations of existing tools in organizing thoughts and tackling complex situations. STS aims to address these shortcomings.Expert Team Our team includes experts in organizational psychology, business strategy, and strategy consulting, bringing diverse experience to inform our interface and processes.Access STS FreeCo-foundersFRANCIS DION  CEOPRIYA BAINS PhD  Chief Revenue OfficerBEN CLAYTON  Chief Engagement OfficerAdvisorsCHRIS COOPER  Change leadership  & strategy consultantPAUL SHAY  Executive at international  non-profitsPATRICIA GIRARD  Startup Founder & PresidentROBI GUHA  Serial tech entrepreneur  & investorALEX NOMBERTO  Business development  & commercial strategistKATRINA MONTINOLA  Fractional and Interim CTO, CAIO, VPEDALE IRONSON, PhD  Management ConsultantJB FOURNIER  Strategy Consultant“It's like ChatGPT on steroids.”YouTubeYouTubeLinkedInLinkedIn ©  STS Strategic Thinking Systems\nDeck Content:\nhttps://storage.googleapis.com/buildship-aic0pe-us-east1/92cc1a5ea6fc4488935e6e11efacb6c6.pdf\n"},"test-workflow-form":{"website":"https://sts42.com","pdfDeckLink":"https://storage.googleapis.com/buildship-aic0pe-us-east1/92cc1a5ea6fc4488935e6e11efacb6c6.pdf"},"7111a5bf-8742-4992-b31c-97bcfb390b79":{"output_format":"text","userRequest":{"hasErrors":false,"_$expression_":"ctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"80488f56-ebe0-4148-a119-366243385f89\"]?.[\"item\"].name as ctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"80488f56-ebe0-4148-a119-366243385f89\"]?.[\"item\"].title associated with ctx?.[\"root\"]?.[\"inputs\"]?.[\"website\"]","type":"text"},"maxTokens":1600,"sessionKey":"","temperature":0.5,"oAuthIntegrations":{},"kbIntegrationKey":"perplexity;;credits","systemPrompt":"research and give brief on the background of provided person name and company\n\nstart response with This what i found about [name]","conversationLimit":2,"model":"sonar-pro"},"3176f735-4d90-4933-b3c9-9e8d2c2b058b":{"model":"gpt-4.1","maxTokens":1000,"oAuthIntegrations":{},"temperature":0.1,"response_schema":{"_$expression_":" ","_$schema_":[{"items":[{"properties":[{"name":"name","type":"string","required":true},{"type":"string","name":"role","required":true}],"required":true,"name":"","type":"object"}],"name":"team","type":"array","required":true},{"required":true,"name":"moat","type":"string"},{"name":"market","required":true,"type":"string"},{"name":"summery","required":true,"type":"string"},{"required":true,"name":"keyDifferentiation","type":"string"},{"required":true,"name":"traction","type":"string"},{"items":[{"required":true,"type":"string","name":""}],"type":"array","name":"redFlags","required":true},{"required":true,"items":[{"name":"","type":"string","required":true}],"name":"highlights","type":"array"},{"type":"array","name":"founders","items":[{"type":"object","properties":[{"type":"string","required":true,"name":"name"},{"name":"role","required":true,"type":"string"}],"required":true,"name":""}],"required":true},{"name":"companyName","type":"string","required":true}],"type":"schema"},"kbIntegrationKey":"openai;;credits","systemPrompt":"Convert the input text of pitch deck into JSON following the schema exactly. If you cant find something in the provided deck you can set it as \"NA\"","userPrompt":{"type":"text","hasErrors":false,"_$expression_":"Website Content:\nctx?.[\"root\"]?.[\"2b8fa1ef-7853-451e-8376-78452c84407b\"]?.[\"f48c51d2-fe21-4f6b-b7cd-310a3fdbac72\"]\nDeck Content:\nctx?.[\"root\"]?.[\"inputs\"]?.[\"pdfDeckLink\"]\n","_$schema_":[]}},"568e4227-7450-4a8b-a861-59b4455d48bf":{"oAuthIntegrations":{},"pdfPath":"","pdfUrl":{"_$keys_":["inputs","pdfDeckLink"]}},"8cfd7e60-42b8-43ce-aa1b-8b6ce7b99542":{"maxTokens":1600,"systemPrompt":"research and give brief on the background of provided person name and company  start response with This what i found about [name]","temperature":0.5,"userRequest":{"hasErrors":false,"type":"text","_$expression_":"ctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"80488f56-ebe0-4148-a119-366243385f89\"]?.[\"item\"].name as ctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"80488f56-ebe0-4148-a119-366243385f89\"]?.[\"item\"].title associated with ctx?.[\"root\"]?.[\"inputs\"]?.[\"website\"]"},"model":"diffbot-small-xl","kbIntegrationKey":"diffbot;;credits","conversationLimit":10,"outputFormat":"text","oAuthIntegrations":{},"sessionKey":""},"test-ab3cd994-21ff-46d8-b06a-8cdc899925ef-form":{"temperature":0.5,"userPrompt":"Value too large to display","conversationLimit":10,"oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"systemPrompt":"given company (Strategic Thinking Systems (STS)) summery: \nSTS (Strategic Thinking Systems) is an AI-driven project planning and alignment platform that helps teams collaborate, align, decide, and plan more efficiently. It offers agentic and copilot AI tools to streamline workflows, enhance productivity, and boost team autonomy, with features like agent chaining, customizable workflows, reusable templates, and actionable AI advisors.\n\nevalute if provided team bios are good product founder fit return analysis and nice markdown with emojis","maxTokens":1600,"modelId":"claude-3-7-sonnet-20250219","kbIntegrationKey":"anthropic;;credits"},"f48c51d2-fe21-4f6b-b7cd-310a3fdbac72":{"url":{"_$keys_":["inputs","website"]},"oAuthIntegrations":{},"selector":"body"},"c7bb3920-50be-4031-a5f6-e333f7054b21":{"fundingData":{"_$keys_":["bdcef193-9e69-4d5f-808d-beafc886fd86"]},"parsedDeck":{"_$keys_":["5195fbc2-557d-4f62-baf6-251b690fea9f","3176f735-4d90-4933-b3c9-9e8d2c2b058b"]},"_$bsStatusCode_":"200","_$bsCacheMaxAge_":0,"productFounderFit":{"_$keys_":["5195fbc2-557d-4f62-baf6-251b690fea9f","ab3cd994-21ff-46d8-b06a-8cdc899925ef"]},"startupScoring":{"_$keys_":["ba37ffeb-278c-4289-a467-b3d155c940b8"]},"competitorSummary":{"_$keys_":["25c02936-87a1-42eb-8d31-039e12e7ec38"]},"startupScoring1":{"_$keys_":["ba37ffeb-278c-4289-a467-b3d155c940b8"]}},"66fec945-2192-4dd9-bb4a-cd22e8eb2181":{"inputs.website":{"_$schema_":[],"_$expression_":"ctx?.[\"root\"]?.[\"66fec945-2192-4dd9-bb4a-cd22e8eb2181\"]?.[\"body\"].website"},"inputs.pdfDeckLink":{"_$expression_":"ctx?.[\"root\"]?.[\"66fec945-2192-4dd9-bb4a-cd22e8eb2181\"]?.[\"body\"].pdfDeckLink","_$schema_":[]},"config.requestContentType":"application/json","config.path":"/deckAnalyzer","config.method":"POST","outputs.body":{"_$keys_":["output"]},"outputs.status":{"_$keys_":["state","_$bsStatusCode_"]},"outputs.cacheMaxAge":{"_$keys_":["state","_$bsCacheMaxAge_"]}},"test-c7ff1f45-2560-4b9e-8c91-d8367530a60f-form":{"oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"output_format":"text","temperature":0.5,"userRequest":"https://sts42.com","kbIntegrationKey":"perplexity;;credits","maxTokens":1600,"systemPrompt":"given website, i want find out if the company has raised any funding rounds previously","sessionKey":"","conversationLimit":2,"model":"sonar-pro"},"834bebe0-75fc-402b-a7c2-0ba572c39d25":{"kbIntegrationKey":"diffbot;;credits"},"test-568e4227-7450-4a8b-a861-59b4455d48bf-form":{"oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"pdfPath":"","pdfUrl":"https://storage.googleapis.com/buildship-aic0pe-us-east1/92cc1a5ea6fc4488935e6e11efacb6c6.pdf"},"ba37ffeb-278c-4289-a467-b3d155c940b8":{"response_schema":{"_$expression_":" ","_$schema_":[{"required":true,"name":"productFounderFitScore","type":"number"},{"type":"number","name":"timingScore","required":true},{"required":true,"name":"tractionScore","type":"number"},{"name":"differentiationScore","type":"number","required":true},{"name":"","type":"string","required":true}],"type":"schema"},"kbIntegrationKey":"openai;;openai-key-1","userPrompt":{"_$expression_":"ctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"3176f735-4d90-4933-b3c9-9e8d2c2b058b\"].companyName\n\nsummery:\nctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"3176f735-4d90-4933-b3c9-9e8d2c2b058b\"]?.[\"summery\"]\nmoat:\nctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"3176f735-4d90-4933-b3c9-9e8d2c2b058b\"]?.[\"moat\"]\nfounder summery:\nctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"ab3cd994-21ff-46d8-b06a-8cdc899925ef\"]\n\nCompetitor ctx?.[\"root\"]?.[\"25c02936-87a1-42eb-8d31-039e12e7ec38\"]\nctx?.[\"root\"]?.[\"25c02936-87a1-42eb-8d31-039e12e7ec38\"]","type":"text","hasErrors":false},"maxTokens":800,"model":"gpt-4.1","temperature":0.1,"oAuthIntegrations":{},"systemPrompt":"Analyze provided company data and return the the presepective score for different matrics out 100 scores in the specified schema, JSON following the schema exactly."},"80488f56-ebe0-4148-a119-366243385f89":{"concurrency":3,"items":{"_$expression_":"ctx?.[\"root\"]?.[\"5195fbc2-557d-4f62-baf6-251b690fea9f\"]?.[\"3176f735-4d90-4933-b3c9-9e8d2c2b058b\"].founders","type":"javascript","hasErrors":false}},"test-7111a5bf-8742-4992-b31c-97bcfb390b79-form":{"output_format":"text","userRequest":"Ben Clayton as undefined associated with https://sts42.com","maxTokens":1600,"sessionKey":"","temperature":0.5,"oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"kbIntegrationKey":"perplexity;;credits","systemPrompt":"research and give brief on the background of provided person name and company\n\nstart response with This what i found about [name]","conversationLimit":2,"model":"sonar-pro"},"e921fb25-0390-467d-9352-8db3d52ed27a":{"sessionKey":"","temperature":0.5,"outputFormat":"text","userRequest":{"_$keys_":["inputs","website"]},"oAuthIntegrations":{},"model":"diffbot-small-xl","kbIntegrationKey":"diffbot;;credits","systemPrompt":"given website, i want find out if the company has raised any funding rounds previously","maxTokens":1600,"conversationLimit":10},"test-f48c51d2-fe21-4f6b-b7cd-310a3fdbac72-form":{"url":"https://sts42.com","oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"selector":"body"},"test-bdcef193-9e69-4d5f-808d-beafc886fd86-form":{"temperature":0.1,"userPrompt":"source A:\n{\"citations\":{\"1\":\"https://sts42.com\",\"2\":\"https://app.sts42.com\",\"3\":\"https://services.sts42.com\",\"4\":\"https://app.sts42.com/auth/signup/\",\"5\":\"https://documentation.sts42.com\",\"6\":\"https://subscribe.sts42.com\",\"7\":\"https://access.sts42.com\",\"8\":\"https://app.sts42.com/auth/forgot-password/\"},\"content\":\"Based on the available information from the provided search results, there is no evidence that Strategic Thinking Systems (STS42) has raised any funding rounds previously. The website and its related pages focus on describing the company's AI-powered solutions, services, pricing, and onboarding processes, but there are no announcements or references to venture capital, seed funding, or any other type of investment round. \\n\\nIf you require confirmation about funding history, you may need to check business databases like Crunchbase or PitchBook, or look for press releases, as this information is not present on the sts42.com website or its associated resources.\"}\n\nsource B:\n**STS42** is a company that focuses on strategic thinking systems, enhancing decision-making processes through AI integration. Unfortunately, there is no specific information available in the search results regarding any funding rounds for **STS42**. The provided search results discuss funding rounds for various other companies and provide general information about funding processes, but do not mention **STS42** specifically. If you need detailed financial information or funding history for **STS42**, it may require accessing more specialized financial databases or company-specific reports.","kbIntegrationKey":"openai;;openai-key-1","oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"maxTokens":800,"systemPrompt":"given two sources of data combine, return json schema, funding ammount number in dollars if no funding(return 0), and reasoning","model":"gpt-4o-2024-08-06","response_schema":{"_$expression_":"{\"type\":\"json_schema\",\"json_schema\":{\"name\":\"response\",\"strict\":true,\"schema\":{\"type\":\"object\",\"properties\":{\"fundingAmount\":{\"type\":\"number\"},\"reasoning\":{\"type\":\"string\"},\"hasFunding\":{\"type\":\"boolean\"}},\"required\":[\"fundingAmount\",\"hasFunding\",\"reasoning\"],\"additionalProperties\":false,\"$schema\":\"http://json-schema.org/draft-07/schema#\"}}}","type":"javascript"}},"1bcf7375-fce3-443b-a6b6-0e431a2282af":{"kbIntegrationKey":"anthropic;;credits"},"test-ba37ffeb-278c-4289-a467-b3d155c940b8-form":{"response_schema":{"_$expression_":"{\"type\":\"json_schema\",\"json_schema\":{\"name\":\"response\",\"strict\":true,\"schema\":{\"type\":\"object\",\"properties\":{\"productFounderFitScore\":{\"type\":\"number\"},\"timingScore\":{\"type\":\"number\"},\"tractionScore\":{\"type\":\"number\"},\"differentiationScore\":{\"type\":\"number\"},\"\":{\"type\":\"string\"}},\"required\":[\"productFounderFitScore\",\"tractionScore\",\"timingScore\",\"differentiationScore\",\"\"],\"additionalProperties\":false,\"$schema\":\"http://json-schema.org/draft-07/schema#\"}}}","type":"javascript"},"kbIntegrationKey":"openai;;openai-key-1","userPrompt":"Value too large to display","maxTokens":800,"model":"gpt-4.1","temperature":0.1,"oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"systemPrompt":"Analyze provided company data and return the the presepective score for different matrics out 100 scores in the specified schema, JSON following the schema exactly."},"test-8cfd7e60-42b8-43ce-aa1b-8b6ce7b99542-form":{"maxTokens":1600,"systemPrompt":"research and give brief on the background of provided person name and company  start response with This what i found about [name]","temperature":0.5,"userRequest":"Ben Clayton as undefined associated with https://sts42.com","model":"diffbot-small-xl","kbIntegrationKey":"diffbot;;credits","conversationLimit":10,"outputFormat":"text","oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"sessionKey":""},"test-25c02936-87a1-42eb-8d31-039e12e7ec38-form":{"maxTokens":1600,"userRequest":"STS (Strategic Thinking Systems) is an AI-driven project planning and alignment platform that helps teams collaborate, align, decide, and plan more efficiently. It offers agentic and copilot AI tools to streamline workflows, enhance productivity, and boost team autonomy, with features like agent chaining, customizable workflows, reusable templates, and actionable AI advisors.","systemPrompt":"given product summery research if you find similar companies, and return a competitor Summary","sessionKey":"","oAuthIntegrations":{"_$expression_":"{}","type":"javascript"},"temperature":0.5,"model":"sonar-pro","kbIntegrationKey":"perplexity;;credits","conversationLimit":2,"output_format":"text"}},"runtimeVersion":"v3","outputs":{"required":[],"properties":{"parsedDeck":{"properties":{},"buildship":{"index":1},"title":"Parsed Deck","type":"object"},"productFounderFit":{"buildship":{"index":1},"type":"string","properties":{},"title":"Product founder fit "},"fundingData":{"properties":{},"buildship":{"index":2},"type":"object","title":"Funding data "},"startupScoring":{"title":"Startup scoring ","properties":{},"buildship":{"index":3},"type":"object"},"competitorSummary":{"title":"Competitor summary ","properties":{},"buildship":{"index":4},"type":"string"},"startupScoring1":{"title":"Startup scoring 1","properties":{},"buildship":{"index":5},"type":"object"}},"type":"object"},"inputs":{"type":"object","required":["string"],"properties":{"website":{"properties":{},"buildship":{"index":1},"type":"string","title":"website"},"pdfDeckLink":{"type":"string","properties":{},"title":"pdfDeckLink","buildship":{"index":0}}}},"variables":{"_$bsCacheMaxAge_":{"type":"number","title":"Flow Output Cache Time","buildship":{"index":0},"default":0,"properties":{}},"_$bsStatusCode_":{"properties":{},"type":"string","title":"Flow Output Status Code","buildship":{"index":0}}}}
